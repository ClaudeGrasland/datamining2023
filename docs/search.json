[
  {
    "objectID": "10-API-INTRO.html",
    "href": "10-API-INTRO.html",
    "title": "Introduction aux API",
    "section": "",
    "text": "library(knitr,warn.conflicts = T,quietly = T)\nlibrary(dplyr, warn.conflicts = T,quietly = T)\n\n\nAttachement du package : 'dplyr'\n\n\nLes objets suivants sont masqués depuis 'package:stats':\n\n    filter, lag\n\n\nLes objets suivants sont masqués depuis 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "10-API-INTRO.html#introduction",
    "href": "10-API-INTRO.html#introduction",
    "title": "Introduction aux API",
    "section": "Introduction",
    "text": "Introduction\n\nDéfinition\nOn peut partir de la définition suivante\n\nEn informatique, API est l’acronyme d’Application Programming Interface, que l’on traduit en français par interface de programmation applicative ou interface de programmation d’application. L’API peut être résumée à une solution informatique qui permet à des applications de communiquer entre elles et de s’échanger mutuellement des services ou des données. Il s’agit en réalité d’un ensemble de fonctions qui facilitent, via un langage de programmation, l’accès aux services d’une application. (Source : Journal du Net)\n\n\n\nFonctions\nUne API peut remplir des fonctions très diverses :\n\nDans le domaine d’internet, l’API permet aux développeurs de pouvoir utiliser un programme sans avoir à se soucier du fonctionnement complexe d’une application. Les API peuvent par exemple être utilisées pour déclencher des campagnes publicitaires d’e-mailing de façon automatique sans avoir à passer par la compréhension d’une telle application (c’est le cas avec l’API AdWords de Google, par exemple). On les retrouve aujourd’hui dans de nombreux logiciels, en particulier dans les systèmes d’exploitation, les serveurs d’applications, dans le monde du graphisme (OpenGL), dans les applications SaaS (Office 365, G Suite, Salesforce…), les bases de données, l’open data, etc.(Source : Journal du Net)\n\n\n\nProtocoles\nD’une manière générale, les API supposent un échange d’informations entre un client et un serveur.\n\nCes échanges d’informations suivent un protocole c’est-à-dire un ensemble de règles. Il existe deux grands protocoles de communication sur lesquels s’adossent les API : Simple Object Access Protocol (SOAP) et Representational State Transfer (REST). Le second s’est désormais largement imposé face au premier car il est plus flexible. Il a donné naissance aux API dites REST ou RESTful (Source : Journal du Net)\n\n\n\nAPI et Data Science\nLe métier de data analyst implique presque nécessairement l’emploi d’API. Les langages de programmation R ou Python ont donc l’un comme l’autre mis au point des packages pour faciliter l’envoi de requêtes sur des serveurs dotés d’API.\n\n«API» est un terme général désignant le lieu où un programme informatique interagit avec un autre ou avec lui-même. Dans ce didacticiel, nous travaillerons spécifiquement avec des API Web, où deux ordinateurs différents - un client et un serveur - interagiront l’un avec l’autre pour demander et fournir des données, respectivement.\n\n\nLes API offrent aux scientifiques des données un moyen raffiné de demander des données propres et organisées à partir d’un site Web. Lorsqu’un site Web comme Facebook met en place une API, il met essentiellement en place un ordinateur qui attend les demandes de données.\n\n\nUne fois que cet ordinateur reçoit une demande de données, il effectuera son propre traitement des données et les enverra à l’ordinateur qui l’a demandé. De notre point de vue en tant que demandeur, nous devrons écrire du code dans R qui crée la demande et indique à l’ordinateur exécutant l’API ce dont nous avons besoin. Cet ordinateur lira ensuite notre code, traitera la requête et renverra des données bien formatées qui peuvent être facilement analysées par les bibliothèques R existantes.\n\n\nPourquoi est-ce précieux? Comparez l’approche API au scraping Web pur. Lorsqu’un programmeur gratte une page Web, il reçoit les données dans un morceau de HTML désordonné. Bien qu’il existe certainement des bibliothèques qui facilitent l’analyse du texte HTML, ce sont toutes des étapes de nettoyage qui doivent être prises avant même de mettre la main sur les données que nous voulons!\n\n\nSouvent, nous pouvons immédiatement utiliser les données que nous obtenons d’une API, ce qui nous fait gagner du temps et de la frustration.\n\nSource : Traduction française d’un billet de Pascual C., 2020"
  },
  {
    "objectID": "10-API-INTRO.html#lapi-de-la-nasa",
    "href": "10-API-INTRO.html#lapi-de-la-nasa",
    "title": "Introduction aux API",
    "section": "l’API de la NASA",
    "text": "l’API de la NASA\nA titre d’exemple, C. Pascual propose de travailler avec l’API Open Notify, qui donne accès à des données sur divers projets de la NASA. À l’aide de l’API Open Notify, nous pouvons notamment en savoir plus sur l’emplacement de la Station spatiale internationale et sur le nombre de personnes actuellement dans l’espace.\n\nInstaller les packages jsonlite et httr\nPour travailler avec des API dans R, nous devons intégrer certaines bibliothèques (library). Ces bibliothèques prennent toutes les complexités d’une requête d’API et les enveloppent dans des fonctions que nous pouvons utiliser dans des lignes de code uniques. Les bibliothèques R que nous utiliserons sont httr et jsonlite. Elles remplissent des rôles différents dans notre introduction des API, mais les deux sont essentiels.Si vous ne disposez pas de ces bibliothèques dans votre console R ou RStudio, vous devez d’abord les télécharger.\n\nlibrary(httr)\nlibrary(jsonlite)\n\n\n\nFormulation d’une requête GET()\nUne requête adressé à une API va suivre le schéma suivant :\n\nknitr::include_graphics(\"img/API_GET.png\",)\n\n\n\n\nIl existe plusieurs types de requêtes que l’on peut adresser à un serveur API. Pour nos besoins, nous allons simplement demander des données, ce qui correspond à une demande GET. Les autres types de requêtes sont POST et PUT, mais nous n’avons pas à nous en préoccuper dans l’immédiat\nAfin de créer une requête GET, nous devons utiliser la fonction GET() de la bibliothèque httr. La fonction GET() nécessite une URL, qui spécifie l’adresse du serveur auquel la demande doit être envoyée.\nNotre programme télécharge les données disponibles à l’adresse du serveur et les stocke dans un objet auquel on peut donner le nom que l’on souhaite, par exemple ovni dans la mesure où le résultat est de prime abord assez mystérieux…\n\novni <- GET(\"http://api.open-notify.org/astros.json\")\nclass(ovni)\n\n[1] \"response\"\n\n\nOn sait que la classe de l’objet est de type response ce qui ne nous avance pas beaucoup.\nToutefois, si on demande à l’objet de s’afficher il nous apporte quatre renseignements utiles\n\novni\n\nResponse [http://api.open-notify.org/astros.json]\n  Date: 2023-03-17 16:53\n  Status: 200\n  Content-Type: application/json\n  Size: 500 B\n\n\n\nDate : le moment exact du téléchargement, très utile pour suivre les mises à jour\nStatus : le code informatique de résultat de la requête. La valeur 200 indique un succès alors que les autres valeurs signaleront un problème.\nContent-Type : le type d’information recueillie. Ici, une application au format json\nSize : la taille du fichier résultant du transfert.\n\nOn poursuit notre enquête en tapant la commande str() qui permet d’avoir plus de détail sur le contenu de l’objet.\n\nstr(ovni)\n\nList of 10\n $ url        : chr \"http://api.open-notify.org/astros.json\"\n $ status_code: int 200\n $ headers    :List of 6\n  ..$ server                     : chr \"nginx/1.10.3\"\n  ..$ date                       : chr \"Fri, 17 Mar 2023 16:53:33 GMT\"\n  ..$ content-type               : chr \"application/json\"\n  ..$ content-length             : chr \"500\"\n  ..$ connection                 : chr \"keep-alive\"\n  ..$ access-control-allow-origin: chr \"*\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ all_headers:List of 1\n  ..$ :List of 3\n  .. ..$ status : int 200\n  .. ..$ version: chr \"HTTP/1.1\"\n  .. ..$ headers:List of 6\n  .. .. ..$ server                     : chr \"nginx/1.10.3\"\n  .. .. ..$ date                       : chr \"Fri, 17 Mar 2023 16:53:33 GMT\"\n  .. .. ..$ content-type               : chr \"application/json\"\n  .. .. ..$ content-length             : chr \"500\"\n  .. .. ..$ connection                 : chr \"keep-alive\"\n  .. .. ..$ access-control-allow-origin: chr \"*\"\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ cookies    :'data.frame':    0 obs. of  7 variables:\n  ..$ domain    : logi(0) \n  ..$ flag      : logi(0) \n  ..$ path      : logi(0) \n  ..$ secure    : logi(0) \n  ..$ expiration: 'POSIXct' num(0) \n  ..$ name      : logi(0) \n  ..$ value     : logi(0) \n $ content    : raw [1:500] 7b 22 6d 65 ...\n $ date       : POSIXct[1:1], format: \"2023-03-17 16:53:33\"\n $ times      : Named num [1:6] 0 0.00291 0.15292 0.15311 0.30212 ...\n  ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n $ request    :List of 7\n  ..$ method    : chr \"GET\"\n  ..$ url       : chr \"http://api.open-notify.org/astros.json\"\n  ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. ..- attr(*, \"names\")= chr \"Accept\"\n  ..$ fields    : NULL\n  ..$ options   :List of 2\n  .. ..$ useragent: chr \"libcurl/7.64.1 r-curl/4.3.2 httr/1.4.3\"\n  .. ..$ httpget  : logi TRUE\n  ..$ auth_token: NULL\n  ..$ output    : list()\n  .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  ..- attr(*, \"class\")= chr \"request\"\n $ handle     :Class 'curl_handle' <externalptr> \n - attr(*, \"class\")= chr \"response\"\n\n\nNous savons désormais que notre objet ovni est une liste comportant 10 branches, elles-mêmes divisées en sous branches qui peuvent être elles-même des listes…\n\n\nRemarque sur les listes\nLes listes sont des objets complexes mais fondamentaux pour la programmation en R. On peut accèder aux branches d’une liste soit en utilisant une série de $ soit en se servant de doubles crochets [[ ]]. Par exemple, si on veut accèder à la date de la réponse on peut taper au choix :\n\novni$headers$date\n\n[1] \"Fri, 17 Mar 2023 16:53:33 GMT\"\n\novni[[\"headers\"]][[\"date\"]]\n\n[1] \"Fri, 17 Mar 2023 16:53:33 GMT\"\n\n\nOn peut également afficher les noms des branches en partant de la racine puis en suivant l’arbre à l’aide de l’instruction names()\n\nnames(ovni$headers)\n\n[1] \"server\"                      \"date\"                       \n[3] \"content-type\"                \"content-length\"             \n[5] \"connection\"                  \"access-control-allow-origin\"\n\n\n\nnames(ovni$fields)\n\nNULL\n\n\n\n\nExtraction des données\nLes données contenues dans la réponse ont été stockées au format JSON (JavaScript Object Notation) qui est devenu un standard pour les échanges de données. Mais elles ont été ensuite comprimées en format binaire pour limiter la taille du fichier transféré. Il va donc falloir procéder en quatre étapes pour les extraire\n\nétape 1 : récupérer les données au format binaire\nOn extrait le champ de données dans la liste. Le résultat est assez étrange :\n\nlibrary(rvest)\ndon_bin<-ovni$content\ndon_bin\n\n  [1] 7b 22 6d 65 73 73 61 67 65 22 3a 20 22 73 75 63 63 65 73 73 22 2c 20 22 6e\n [26] 75 6d 62 65 72 22 3a 20 31 30 2c 20 22 70 65 6f 70 6c 65 22 3a 20 5b 7b 22\n [51] 63 72 61 66 74 22 3a 20 22 49 53 53 22 2c 20 22 6e 61 6d 65 22 3a 20 22 53\n [76] 65 72 67 65 79 20 50 72 6f 6b 6f 70 79 65 76 22 7d 2c 20 7b 22 63 72 61 66\n[101] 74 22 3a 20 22 49 53 53 22 2c 20 22 6e 61 6d 65 22 3a 20 22 44 6d 69 74 72\n[126] 79 20 50 65 74 65 6c 69 6e 22 7d 2c 20 7b 22 63 72 61 66 74 22 3a 20 22 49\n[151] 53 53 22 2c 20 22 6e 61 6d 65 22 3a 20 22 46 72 61 6e 6b 20 52 75 62 69 6f\n[176] 22 7d 2c 20 7b 22 63 72 61 66 74 22 3a 20 22 53 68 65 6e 7a 68 6f 75 20 31\n[201] 35 22 2c 20 22 6e 61 6d 65 22 3a 20 22 46 65 69 20 4a 75 6e 6c 6f 6e 67 22\n[226] 7d 2c 20 7b 22 63 72 61 66 74 22 3a 20 22 53 68 65 6e 7a 68 6f 75 20 31 35\n[251] 22 2c 20 22 6e 61 6d 65 22 3a 20 22 44 65 6e 67 20 51 69 6e 67 6d 69 6e 67\n[276] 22 7d 2c 20 7b 22 63 72 61 66 74 22 3a 20 22 53 68 65 6e 7a 68 6f 75 20 31\n[301] 35 22 2c 20 22 6e 61 6d 65 22 3a 20 22 5a 68 61 6e 67 20 4c 75 22 7d 2c 20\n[326] 7b 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 2c 20 22 6e 61 6d 65 22 3a 20\n[351] 22 53 74 65 70 68 65 6e 20 42 6f 77 65 6e 22 7d 2c 20 7b 22 63 72 61 66 74\n[376] 22 3a 20 22 49 53 53 22 2c 20 22 6e 61 6d 65 22 3a 20 22 57 61 72 72 65 6e\n[401] 20 48 6f 62 75 72 67 22 7d 2c 20 7b 22 63 72 61 66 74 22 3a 20 22 49 53 53\n[426] 22 2c 20 22 6e 61 6d 65 22 3a 20 22 53 75 6c 74 61 6e 20 41 6c 6e 65 79 61\n[451] 64 69 22 7d 2c 20 7b 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 2c 20 22 6e\n[476] 61 6d 65 22 3a 20 22 41 6e 64 72 65 79 20 46 65 64 79 61 65 76 22 7d 5d 7d\n\n\n\n\nétape 2 : convertir les données binaires au format caractère\nLa conversion est effectuée à l’aide de la fonction rawToChar() qui fait partie de R-Base.\n\n# conversion du contenu de toto en mode character\ndon_car<-rawToChar(don_bin)\ndon_car\n\n[1] \"{\\\"message\\\": \\\"success\\\", \\\"number\\\": 10, \\\"people\\\": [{\\\"craft\\\": \\\"ISS\\\", \\\"name\\\": \\\"Sergey Prokopyev\\\"}, {\\\"craft\\\": \\\"ISS\\\", \\\"name\\\": \\\"Dmitry Petelin\\\"}, {\\\"craft\\\": \\\"ISS\\\", \\\"name\\\": \\\"Frank Rubio\\\"}, {\\\"craft\\\": \\\"Shenzhou 15\\\", \\\"name\\\": \\\"Fei Junlong\\\"}, {\\\"craft\\\": \\\"Shenzhou 15\\\", \\\"name\\\": \\\"Deng Qingming\\\"}, {\\\"craft\\\": \\\"Shenzhou 15\\\", \\\"name\\\": \\\"Zhang Lu\\\"}, {\\\"craft\\\": \\\"ISS\\\", \\\"name\\\": \\\"Stephen Bowen\\\"}, {\\\"craft\\\": \\\"ISS\\\", \\\"name\\\": \\\"Warren Hoburg\\\"}, {\\\"craft\\\": \\\"ISS\\\", \\\"name\\\": \\\"Sultan Alneyadi\\\"}, {\\\"craft\\\": \\\"ISS\\\", \\\"name\\\": \\\"Andrey Fedyaev\\\"}]}\"\n\n\nOn commence à mieux voir le résultat mais ce n’est pas encore très lisible car il s’agit de données au format JSON\n\n\nétape 3 : convertir les données JSON en objet R\nOn convertit les données de type JSON en données utilisables par R à l’aide de la fonction fromJson() du package jsonlite()\n\ndon_R <- fromJSON(don_car)\nstr(don_R)\n\nList of 3\n $ message: chr \"success\"\n $ number : int 10\n $ people :'data.frame':    10 obs. of  2 variables:\n  ..$ craft: chr [1:10] \"ISS\" \"ISS\" \"ISS\" \"Shenzhou 15\" ...\n  ..$ name : chr [1:10] \"Sergey Prokopyev\" \"Dmitry Petelin\" \"Frank Rubio\" \"Fei Junlong\" ...\n\n\nOn obtient finalement une liste de trois éléments dont le dernier est un data.frame décrivant les astronautes présents dans la station spatiale internationale au moment de l’execution du programme.\n\n\nétape 4 : Récupérer le tableau de résultats\n\ntab<-don_R$people\nkable(tab,caption = \"Passagers de l'ISS en temps réel\")\n\n\nPassagers de l’ISS en temps réel\n\n\ncraft\nname\n\n\n\n\nISS\nSergey Prokopyev\n\n\nISS\nDmitry Petelin\n\n\nISS\nFrank Rubio\n\n\nShenzhou 15\nFei Junlong\n\n\nShenzhou 15\nDeng Qingming\n\n\nShenzhou 15\nZhang Lu\n\n\nISS\nStephen Bowen\n\n\nISS\nWarren Hoburg\n\n\nISS\nSultan Alneyadi\n\n\nISS\nAndrey Fedyaev\n\n\n\n\n\n\n\n\nEcriture d’une fonction\nUne fois que l’on a bien compris la procédure d’extraction de cette API, on peut construire une fonction d’extraction pour simplifier la tâche et l’automatiser :\n\n## Fonction\nextract_ISS <- function(){\n  ovni <- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin<-ovni$content\n  don_char<-rawToChar(don_bin)\n  don_R<-fromJSON(don_char)\n  tab<-don_R$people\n  return(tab)\n}\n\n## Application\nextract_ISS()\n\n         craft             name\n1          ISS Sergey Prokopyev\n2          ISS   Dmitry Petelin\n3          ISS      Frank Rubio\n4  Shenzhou 15      Fei Junlong\n5  Shenzhou 15    Deng Qingming\n6  Shenzhou 15         Zhang Lu\n7          ISS    Stephen Bowen\n8          ISS    Warren Hoburg\n9          ISS  Sultan Alneyadi\n10         ISS   Andrey Fedyaev\n\n\nOn peut améliorer la fonction en lui faisant ajouter un champ qui indique la date à laquelle a été effectué le relevé :\n\n## Fonction\nextract_ISS2 <- function(){\n  ovni <- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin<-ovni$content\n  don_char<-rawToChar(don_bin)\n  don_R<-fromJSON(don_char)\n  tab<-don_R$people\n  tab$date<-ovni$headers$date\n  return(tab)\n}\n\n## Application\nextract_ISS2()\n\n         craft             name                          date\n1          ISS Sergey Prokopyev Fri, 17 Mar 2023 16:53:34 GMT\n2          ISS   Dmitry Petelin Fri, 17 Mar 2023 16:53:34 GMT\n3          ISS      Frank Rubio Fri, 17 Mar 2023 16:53:34 GMT\n4  Shenzhou 15      Fei Junlong Fri, 17 Mar 2023 16:53:34 GMT\n5  Shenzhou 15    Deng Qingming Fri, 17 Mar 2023 16:53:34 GMT\n6  Shenzhou 15         Zhang Lu Fri, 17 Mar 2023 16:53:34 GMT\n7          ISS    Stephen Bowen Fri, 17 Mar 2023 16:53:34 GMT\n8          ISS    Warren Hoburg Fri, 17 Mar 2023 16:53:34 GMT\n9          ISS  Sultan Alneyadi Fri, 17 Mar 2023 16:53:34 GMT\n10         ISS   Andrey Fedyaev Fri, 17 Mar 2023 16:53:34 GMT\n\n\nEt si on est à l’aise avec les listes, on peut aussi exporter les résultats sous la forme d’une liste plutôt que d’un tableau, ce qui évite de répéter plusieurs fois la date d’extraction des données\n\n## Fonction\nextract_ISS3 <- function(){\n  ovni <- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin<-ovni$content\n  don_char<-rawToChar(don_bin)\n  don_R<-fromJSON(don_char)\n  tab<-don_R$people\n  date<-ovni$headers$date\n  result<-list(\"Update\" = date,\"Data\" =tab)\n  return(result)\n}\n\n## Application\nx<-extract_ISS3()\nkable(x$Data, caption=paste(\"Passagers de l'ISS :\", x$Update))\n\n\nPassagers de l’ISS : Fri, 17 Mar 2023 16:53:34 GMT\n\n\ncraft\nname\n\n\n\n\nISS\nSergey Prokopyev\n\n\nISS\nDmitry Petelin\n\n\nISS\nFrank Rubio\n\n\nShenzhou 15\nFei Junlong\n\n\nShenzhou 15\nDeng Qingming\n\n\nShenzhou 15\nZhang Lu\n\n\nISS\nStephen Bowen\n\n\nISS\nWarren Hoburg\n\n\nISS\nSultan Alneyadi\n\n\nISS\nAndrey Fedyaev\n\n\n\n\n\n\n\nAPI et mise à jour en temps réel\nSur le site web du billet proposé par C. Pascual en février 2020, on trouve une autre liste ne comportant que 6 passagers et avec des noms totalement différents :\n\n\n\nPassagers de l’ISS en février 2020\n\n\ncraft\nname\n\n\n\n\nISS\nChristina Koch\n\n\nISS\nAlexander Skvortsov\n\n\nISS\nLuca Parmitano\n\n\nISS\nAndrew Morgan\n\n\nISS\nOleg Skripochka\n\n\nISS\nJessica Meir\n\n\n\n\n\nEn effet, l’API renvoie les résultats au moment de l’execution de la fonction GET() ce qui correspond à février 2020 pour le billet de blog. Or, les astronautes sont remplacés au plus tous les six mois ce qui explique que tous les noms soient différents un an après.\nNB : Cet exemple permet de mettre en évidence une fonction centrale des API qui est la mise à jour en temps réel des données !"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html",
    "href": "11-API-OPENDATASOFT.html",
    "title": "L’API opendatasoft",
    "section": "",
    "text": "L’objectif de ce chapitre est d’examiner en détail le fonctionnement du site public.opendatasoft qui permet d’accèder à des centaines d’API à l’aide de requêtes normalisées. Sans apprendre en détail le fonctionnement de cette API, on va montrer comment créer de petites fonctions facilitant le travail d’exportation des variables ou des données.\nOn charge les packages utiles :"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#liste-des-api",
    "href": "11-API-OPENDATASOFT.html#liste-des-api",
    "title": "L’API opendatasoft",
    "section": "Liste des API",
    "text": "Liste des API\nLa première étape consiste à choisir l’API qui nous intéresse parmi plus de 600.\n\nEn parcourant le site\nOn peut se rendre sur le site pour parcourir les API proposées en allant à l’adresse : https://public.opendatasoft.com\n\n\n\n\n\n\n\nEn récupérant le catalogue\nMais il est également possible de téécharger le catalogue général … en se servant d’une API\n\nx<-GET('https://public.opendatasoft.com/api/datasets/1.0/search/?q=&rows=1000&start=0')\ny<-fromJSON(rawToChar((x$content)))\ncat<-y$datasets$metas\nrow.names(cat)<-y$datasets$datasetid\nkable(head(cat[,c(12,1,6,7,8)]),row.names = F)\n\n\n\n\n\n\n\n\n\n\n\nkeyword\ndomain\nmodified\nlicense\npublisher\n\n\n\n\nActes budgétaires, Collectivité , M14 , M52 , M57\npublic\n2019-03-06T10:33:30+00:00\nPublic domain\nDirection Générale des Collectivités Locales (DGCL)\n\n\nprovincie, kadaster\npublic\n2021-10-20T07:54:50+00:00\nCC 0 1.0\nOpendatasoft\n\n\ncountry , boundary , Natural Earth\npublic\n2020-03-04T12:35:21+00:00\nPublic domain\nNatural Earth\n\n\nnomenclature des actes budgétaires, collectivités locales , comptabilité , plan de comptes , Totem\npublic\n2021-06-09T11:27:44+00:00\nOpen License v2.0\nDirection Générale des Collectivités Locales (DGCL)\n\n\nsubdistrict, nafa , nafot , county , department\npublic\n2022-04-14T00:23:01+00:00\nNA\nOpendatasoft\n\n\nProduction, déchets\npublic\n2017-11-30T16:21:07+00:00\nOpen License v1.0\nMinistère de l’Écologie, du Développement durable et de l’Énergie\n\n\n\n\n\nOn suppose que le choix s’est porté sur l’API arbresremarquablesparis2011"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#liste-des-variables-dune-api",
    "href": "11-API-OPENDATASOFT.html#liste-des-variables-dune-api",
    "title": "L’API opendatasoft",
    "section": "Liste des variables d’une API",
    "text": "Liste des variables d’une API\nAvant de télécharger les données, on effectue une requête pour connaître les variables du tableau que l’on va télécharger ainsi que les variables pouvant servir de “facettes” c’est-à-dire permettant d’effectuer des requêtes.\n\nProgramme\n\ntab<-\"arbresremarquablesparis2011\"\nurl<-paste(\"https://public.opendatasoft.com/api/v2/catalog/datasets/\",tab,\"?\",sep=\"\")\nx<-GET(url)\ny<-fromJSON(rawToChar(x$content))\nvar<-y$dataset$fields\n\nhead(var)\n\n             name           label   type annotations.facet\n1          idbase          IDBASE double                NA\n2 libellefrancais LIBELLEFRANCAIS   text              TRUE\n3           genre           GENRE   text              TRUE\n4          espece          ESPECE   text              TRUE\n5         adresse         ADRESSE   text                NA\n6 typeemplacement TYPEEMPLACEMENT   text                NA\n  annotations.hierarchical annotations.unit annotations.facetsort\n1                     <NA>             <NA>                  <NA>\n2                     <NA>             <NA>                  <NA>\n3                        /             <NA>                  <NA>\n4                        /             <NA>                  <NA>\n5                     <NA>             <NA>                  <NA>\n6                     <NA>             <NA>                  <NA>\n  annotations.timeserie_precision description\n1                            <NA>          NA\n2                            <NA>          NA\n3                            <NA>          NA\n4                            <NA>          NA\n5                            <NA>          NA\n6                            <NA>          NA\n\n\nLe tableau est correct, mais il présente une structure inhabituelle puisqu’on trouve un dataframe à l’intérieur de chaque ligne de la variable annotations. On va donc éviter les ennuis en ne gardant que les deux premières colonnes\n\nvar <- var  %>% select(-annotations)\nkable(var)\n\n\n\n\nname\nlabel\ntype\ndescription\n\n\n\n\nidbase\nIDBASE\ndouble\nNA\n\n\nlibellefrancais\nLIBELLEFRANCAIS\ntext\nNA\n\n\ngenre\nGENRE\ntext\nNA\n\n\nespece\nESPECE\ntext\nNA\n\n\nadresse\nADRESSE\ntext\nNA\n\n\ntypeemplacement\nTYPEEMPLACEMENT\ntext\nNA\n\n\ndomanialite\nDOMANIALITE\ntext\nNA\n\n\narrondissement\nARRONDISSEMENT\ntext\nNA\n\n\ncomplementadresse\nCOMPLEMENTADRESSE\ntext\nNA\n\n\nnumero\nNUMERO\ntext\nNA\n\n\nidemplacement\nIDEMPLACEMENT\ntext\nNA\n\n\ncirconferenceencm\nCIRCONFERENCE EN CM\ndouble\nNA\n\n\nhauteurenm\nHAUTEUR EN M\ndouble\nNA\n\n\nstadedeveloppement\nSTADEDEVELOPPEMENT\ntext\nNA\n\n\npepiniere\nPEPINIERE\ntext\nNA\n\n\nvarieteoucultivar\nVARIETE OU CULTIVAR\ntext\nNA\n\n\ndateplantation\nDATEPLANTATION\ndatetime\nNA\n\n\nremarquable\nREMARQUABLE\ntext\nNA\n\n\ngeom_x_y\nGeo point\ngeo_point_2d\nNA\n\n\n\n\n\n\n\nFonction\nOn le transforme en fonction pour un usage plus simple :\n\nget_variables<-function(idtab = \"arbresremarquablesparis2011\") {\n  url<-paste(\"https://public.opendatasoft.com/api/v2/catalog/datasets/\",idtab,\"?\",sep=\"\")\n  x<-GET(url)\n  y<-fromJSON(rawToChar((x$content)))\n  var<-y$dataset$fields\n  var <- var %>% select(-annotations)\n  return(var)\n}\n\nOn peut désormais appliquer notre fonction sur n’importe quel autre tableau du catalogue. Par exemple, si on choisit le tableau qualite_de-lair-france on obtient la liste de variables suivante :\n\nvar<-get_variables(\"qualite-de-lair-france\")\nkable(var)\n\n\n\n\nname\nlabel\ntype\ndescription\n\n\n\n\ncountry\nCountry Code\ntext\nNA\n\n\ncity\nCity\ntext\nNA\n\n\nlocation\nLocation\ntext\nNA\n\n\ncoordinates\nCoordinates\ngeo_point_2d\nNA\n\n\nmeasurements_parameter\nPollutant\ntext\nNA\n\n\nmeasurements_sourcename\nSource Name\ntext\nNA\n\n\nmeasurements_unit\nUnit\ntext\nNA\n\n\nmeasurements_value\nValue\ndouble\nNA\n\n\nmeasurements_lastupdated\nLast Updated\ndatetime\nNA\n\n\ncountry_name_en\nCountry Label\ntext\nNA"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#récupération-des-données",
    "href": "11-API-OPENDATASOFT.html#récupération-des-données",
    "title": "L’API opendatasoft",
    "section": "Récupération des données",
    "text": "Récupération des données\n\nProgramme\nPar défaut, une API renvoie 10 enregistrements, ce qui permet de se faire une première idée de la structure des données\n\n x<-GET(\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=arbresremarquablesparis2011&q=&rows=10\")\ny<-fromJSON(rawToChar((x$content)))\n  don<-y$records$fields\nkable(don)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhauteurenm\ngeom_x_y\ncirconferenceencm\nstadedeveloppement\nremarquable\ngenre\npepiniere\ndateplantation\ntypeemplacement\narrondissement\ncomplementadresse\nidemplacement\nlibellefrancais\ndomanialite\nadresse\nespece\nidbase\nvarieteoucultivar\n\n\n\n\n30\n48.839405, 2.433374\n310\nMature\nOUI\nLiriodendron\nInconnue\n1862-01-01T00:09:21+00:00\nArbre\nBOIS DE VINCENNES\n12-02\n12-02\nTulipier\nJardin\nSQUARE CARNOT - AVENUE DAUMESNIL / ESPLANADE DU CHATEAU DE VINCENNES\ntulipifera\n2002370\nNA\n\n\n22\n48.868573, 2.313326\n209\nMature\nOUI\nCalocedrus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 8E ARRDT\nSecteur Marigny\n000103002\nLibocèdre\nJardin\nJARDINS DES CHAMPS ELYSEES - SQUARE MARIGNY / 41 AVENUE GABRIEL\ndecurrens\n307478\nNA\n\n\n6\n48.858754, 2.295499\n205\nAdulte\nOUI\nFagus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 7E ARRDT\nCanton 03 / SETE\nP00306006\nHêtre\nJardin\nJARDIN DU CHAMP DE MARS ET PELOUSES DE L ECOLE MILITAIRE / SETE\nsylvatica\n108183\n‘’Pendula’’\n\n\n20\n48.822604, 2.336701\n400\nMature\nOUI\nFagus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 14E ARRDT\nGrande pelouse\n031302006\nHêtre\nJardin\nPARC MONTSOURIS / 28 BOULEVARD JOURDAN\nsylvatica\n113328\n‘’Riversii’’\n\n\n12\n48.847611, 2.253143\n132\nAdulte\nOUI\nFirmiana\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 16E ARRDT\nNA\n00030001\nSterculier\nJardin\nJARDIN DES SERRES D AUTEUIL / 1 AVENUE GORDON BENNETT\nsimplex\n136446\nNA\n\n\n13\n48.857417, 2.314725\n155\nAdulte\nOUI\nMagnolia\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 7E ARRDT\n07-10\n000202001\nMagnolia\nJardin\nSQUARE D AJACCIO / 127 RUE DE GRENELLE\ngrandiflora\n109016\nNA\n\n\n7\n48.868295, 2.363189\n53\nJeune (arbre)\nOUI\nQuercus\nGUILLOT BOURNE\n2017-11-09T01:00:00+00:00\nArbre\nPARIS 10E ARRDT\nNA\n000401009\nChêne\nAlignement\nPLACE DE LA REPUBLIQUE\ncerris\n2017817\nNA\n\n\n30\n48.880335, 2.381305\n725\nMature\nOUI\nPlatanus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 19E ARRDT\n19-08\nH0690012\nPlatane\nJardin\nPARC DES BUTTES CHAUMONT\nx hispanica\n102141\nNA\n\n\n25\n48.863391, 2.240481\n468\nMature\nOUI\nCedrus\nInconnue\n1862-01-01T00:09:21+00:00\nArbre\nBOIS DE BOULOGNE\n16-09\n000301002\nCèdre\nJardin\nGRANDE CASCADE - CARREFOUR DE LONGCHAMP\nlibani\n2002348\nNA\n\n\n31\n48.87858, 2.30756\n645\nMature\nOUI\nPlatanus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 8E ARRDT\n08-02\n00SO0222\nPlatane\nJardin\nPARC MONCEAU\norientalis\n313940\nNA\n\n\n\n\n\n\n\nFonction\nOn peut ensuite écrire une fonction qui précise le nombre d’enregistrements à lire avec le paramètre raws= et le point de départ de la lecture avec le paramètre start= (sachant que le premier enregistrement correspond à la valeur 0). On pourra ensuite procéder à des téléchargements successifs en évitant de dépasser la valeur raws=10000 car en génral cela bloque le fonctionnement des API. Pour télécharger un tableau ayant plus de 10000 lignes, il faudra de préférence créer une boucle qui ramène des paquets de 10000.\n\nget_data<-function(idtab = \"arbresremarquablesparis2011\",\n                  rows=10,\n                  start=0) {\n  url<-paste0(\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=\",idtab,\"&q=&rows=\",rows,\"&start=\",start,sep=\"\")\n  x<-GET(url)\n  y<-fromJSON(rawToChar((x$content)))\n  don<-y$records$fields\n  return(don)\n}\n\nDans le cas du tableau des arbres remarquables à paris, il n’y a que 178 enregistrements et il suffit donc de mettre une valeur de raws supérieure pour récupérer tout le tableau :\n\ndon_arbres <- get_data(idtab = \"arbresremarquablesparis2011\",\n                      rows=1000,\n                      start=0)\ndim(don_arbres)\n\n[1] 174  18\n\nkable(head(don_arbres))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhauteurenm\ngeom_x_y\ncirconferenceencm\nstadedeveloppement\nremarquable\ngenre\npepiniere\ndateplantation\ntypeemplacement\narrondissement\ncomplementadresse\nidemplacement\nlibellefrancais\ndomanialite\nadresse\nespece\nidbase\nvarieteoucultivar\n\n\n\n\n30\n48.839405, 2.433374\n310\nMature\nOUI\nLiriodendron\nInconnue\n1862-01-01T00:09:21+00:00\nArbre\nBOIS DE VINCENNES\n12-02\n12-02\nTulipier\nJardin\nSQUARE CARNOT - AVENUE DAUMESNIL / ESPLANADE DU CHATEAU DE VINCENNES\ntulipifera\n2002370\nNA\n\n\n22\n48.868573, 2.313326\n209\nMature\nOUI\nCalocedrus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 8E ARRDT\nSecteur Marigny\n000103002\nLibocèdre\nJardin\nJARDINS DES CHAMPS ELYSEES - SQUARE MARIGNY / 41 AVENUE GABRIEL\ndecurrens\n307478\nNA\n\n\n6\n48.858754, 2.295499\n205\nAdulte\nOUI\nFagus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 7E ARRDT\nCanton 03 / SETE\nP00306006\nHêtre\nJardin\nJARDIN DU CHAMP DE MARS ET PELOUSES DE L ECOLE MILITAIRE / SETE\nsylvatica\n108183\n‘’Pendula’’\n\n\n20\n48.822604, 2.336701\n400\nMature\nOUI\nFagus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 14E ARRDT\nGrande pelouse\n031302006\nHêtre\nJardin\nPARC MONTSOURIS / 28 BOULEVARD JOURDAN\nsylvatica\n113328\n‘’Riversii’’\n\n\n12\n48.847611, 2.253143\n132\nAdulte\nOUI\nFirmiana\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 16E ARRDT\nNA\n00030001\nSterculier\nJardin\nJARDIN DES SERRES D AUTEUIL / 1 AVENUE GORDON BENNETT\nsimplex\n136446\nNA\n\n\n13\n48.857417, 2.314725\n155\nAdulte\nOUI\nMagnolia\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 7E ARRDT\n07-10\n000202001\nMagnolia\nJardin\nSQUARE D AJACCIO / 127 RUE DE GRENELLE\ngrandiflora\n109016\nNA\n\n\n\n\n\nSi l’on prend l’exemple de la qualité de l’air, le tableau est nettement plus grand mais reste sous la valeur de 10000 enregistrements\n\ndon_air <- get_data(idtab = \"qualite-de-lair-france\",\n                      rows=10000,\n                      start=0)\ndim(don_air)\n\n[1] 1698   10\n\nkable(head(don_air))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmeasurements_unit\nmeasurements_value\ncoordinates\nmeasurements_sourcename\nmeasurements_lastupdated\nmeasurements_parameter\ncountry_name_en\ncountry\nlocation\ncity\n\n\n\n\nµg/m³\n40.7\n45.569452, 5.932986\nEEA France\n2023-03-17T01:00:00+00:00\nNO2\nFrance\nFR\nFR33105\nSavoie\n\n\nµg/m³\n99.3\n45.420088, 4.395421\nEEA France\n2023-03-17T01:00:00+00:00\nO3\nFrance\nFR\nFR29424\nLoire\n\n\nµg/m³\n5.6\n45.774838, 4.898576\nEEA France\n2023-03-17T01:00:00+00:00\nNO2\nFrance\nFR\nFR20069\nRhône\n\n\nµg/m³\n7.1\n48.513488, -2.749527\nEEA France\n2023-03-16T20:00:00+00:00\nPM2.5\nFrance\nFR\nFR19061\nCôtes-d’Armor\n\n\nµg/m³\n11.1\n49.5027376, 0.2324858\nEEA France\n2023-03-17T01:00:00+00:00\nPM10\nFrance\nFR\nFR05083\nSeine-Maritime\n\n\nµg/m³\n13.2\n47.247461, -1.936615\nEEA France\n2023-03-17T01:00:00+00:00\nPM10\nFrance\nFR\nFR23068\nLoire-Atlantique\n\n\n\n\n\nPar contre la base SIRENE comporte 34 millions d’enregistrement et il va être impossible de la télécharger d’un coup à l’aide d’une API. Dès que la valeur rows dépasse 10000, l’API refuse de renvoyer les résultats\n\ndon_sir <- get_data(idtab = \"sirene_v3\",\n                      rows=10001,\n                      start=0)\ndim(don_sir)\n\nNULL"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#sélection-ou-exclusion",
    "href": "11-API-OPENDATASOFT.html#sélection-ou-exclusion",
    "title": "L’API opendatasoft",
    "section": "Sélection ou exclusion",
    "text": "Sélection ou exclusion\nL’intérêt principal d’une API est de procéder à des sélections d’enregistrement en amont de leur téléchargement. On va utiliser pour cela les facettes qui correspondent aux variables pour lesquelles l’API a prévu des index permettant une extraction rapide.\n\nSélection\nSupposons par exemple qu’on ne veuille extraire que les arbres remarquables de la famille des chênes (genre = Quercus). Cela correspond à l’ajout à la fin de l’instruction GET d’une instruction refine prenant ici la forme refine.genre=Quercus.\n\nx<- GET(\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=arbresremarquablesparis2011&q=&rows=100&refine.genre=Quercus\")\n  y<-fromJSON(rawToChar((x$content)))\n  don<-y$records$fields\n  kable(don)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhauteurenm\ngeom_x_y\ncirconferenceencm\nstadedeveloppement\nremarquable\ngenre\npepiniere\ndateplantation\ntypeemplacement\narrondissement\nidemplacement\nlibellefrancais\ndomanialite\nadresse\nespece\nidbase\ncomplementadresse\n\n\n\n\n7\n48.868295, 2.363189\n53\nJeune (arbre)\nOUI\nQuercus\nGUILLOT BOURNE\n2017-11-09T01:00:00+00:00\nArbre\nPARIS 10E ARRDT\n000401009\nChêne\nAlignement\nPLACE DE LA REPUBLIQUE\ncerris\n2017817\nNA\n\n\n23\n48.818389, 2.437919\n255\nMature\nOUI\nQuercus\nInconnue\n1860-01-01T00:09:21+00:00\nArbre\nBOIS DE VINCENNES\n12-15\nChêne\nJardin\nPENTE DE GRAVELLE - AVENUE DE GRAVELLE / ROUTE NOUVELLE\nilex\n2002385\n12-15\n\n\n30\n48.834174, 2.461321\n431\nMature\nOUI\nQuercus\nInconnue\n1784-01-01T00:09:21+00:00\nArbre\nBOIS DE VINCENNES\n12-25\nChêne\nJardin\nLAC DES MINIMES - ROUTE RONDE DES MINIMES\nrobur\n2002376\n12-25\n\n\n10\n48.873681, 2.290252\n207\nMature\nOUI\nQuercus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 16E ARRDT\n000206003\nChêne\nJardin\nJARDIN DE L AVENUE FOCH / 10 AVENUE FOCH\nilex\n114867\nPELOUSE 10 - 20 à 26\n\n\n30\n48.843308, 2.449743\n465\nMature\nOUI\nQuercus\nInconnue\n1815-01-01T00:09:21+00:00\nArbre\nBOIS DE VINCENNES\n12-26\nChêne\nJardin\nFORT NEUF - AVENUE DE LA PEPINIERE / ROUTE DU GRAND MARECHAL\nrobur\n2002375\n12-26\n\n\n15\n48.833021, 2.349918\n140\nAdulte\nOUI\nQuercus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 13E ARRDT\n000301002\nChêne\nJardin\nSQUARE RENE LE GALL / 1 RUE EMILE DESLANDRES\ncerris\n104839\nRoseraie\n\n\n15\n48.839644, 2.300976\n180\nAdulte\nOUI\nQuercus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 15E ARRDT\n000106001\nChêne\nJardin\nSQUARE DE LA PLACE ADOLPHE CHERIOUX / 260 RUE DE VAUGIRARD\nfrainetto\n113597\nNA\n\n\n11\n48.847173, 2.252866\n232\nMature\nOUI\nQuercus\nInconnue\n1895-01-01T00:09:21+00:00\nArbre\nPARIS 16E ARRDT\n00040054\nChêne\nJardin\nJARDIN DES SERRES D AUTEUIL / 1 AVENUE GORDON BENNETT\nsuber subsp. Occidentalis\n136338\nNA\n\n\n13\n48.84657, 2.25242\n237\nMature\nOUI\nQuercus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 16E ARRDT\n00040039\nChêne\nJardin\nJARDIN DES SERRES D AUTEUIL / 1 AVENUE GORDON BENNETT\nilex\n136323\nNA\n\n\n15\n48.821839, 2.335786\n255\nMature\nOUI\nQuercus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 14E ARRDT\n0311B1011\nChêne\nJardin\nPARC MONTSOURIS / 28 BOULEVARD JOURDAN\nilex\n110934\nVolcan / Puits\n\n\n14\n48.838816, 2.406567\n169\nAdulte\nOUI\nQuercus\nInconnue\n1990-01-01T01:00:00+00:00\nArbre\nPARIS 12E ARRDT\n000202001\nChêne\nJardin\nSQUARE CHARLES PEGUY / 21 RUE ROTTEMBOURG\nfrainetto\n123156\nNA\n\n\n\n\n\n\n\nExclusion\nOn peut de la même manière exclure au lieu de sélectionner en utilisant l’instruction exclude. Par exemple, on peut retirer les deux bois de Vincennes et de Boulogne qui sont identifiés dans la variable arrondissement. Il ne rste plus alors que 130 arbres remarquables au lieu de 178.\n\nx<- GET(\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=arbresremarquablesparis2011&q=&rows=1000&exclude.arrondissement=BOIS+DE+VINCENNES&exclude.arrondissement=BOIS+DE+BOULOGNE\")\n  y<-fromJSON(rawToChar((x$content)))\n  don<-y$records$fields\n dim(don)\n\n[1] 126  18\n\n table(don$arrondissement)\n\n\nPARIS 10E ARRDT PARIS 11E ARRDT PARIS 12E ARRDT PARIS 13E ARRDT PARIS 14E ARRDT \n              1               1               3               4              10 \nPARIS 15E ARRDT PARIS 16E ARRDT PARIS 17E ARRDT PARIS 18E ARRDT PARIS 19E ARRDT \n              6              27               8              10              10 \nPARIS 1ER ARRDT PARIS 20E ARRDT  PARIS 3E ARRDT  PARIS 4E ARRDT  PARIS 5E ARRDT \n              1              14               3               5               6 \n PARIS 6E ARRDT  PARIS 7E ARRDT  PARIS 8E ARRDT  PARIS 9E ARRDT \n              1               9               5               2 \n\n\n\n\nSélection géographique\nUne autre possibilité offerte par l’application est d’extraire des enregistrements en fonction d’une localisation géographique et d’une distance maximale à celle-ci. Supposons par exemple que l’on souhaite trouver l’ensemble des arbres remarquables dans un rayon de 2 km autour du bâtiment Olympe de Gouges situé place Paul Ricoeur dans le 13e arrondissement. Pour résoudre le problème, on commence par déterminer les coordonnées du lieu cible ce qui peut se faire par un click droit dans une Google Map :\n\nknitr::include_graphics(\"img/coord_odg.png\")\n\n\n\n\nOn passe ensuite une requête incluant le paramètre geofilter.distance()assortie des trois paramètres de latitude (en degré décimal), longitude (en degré décimal) et distance (en mètres) avec comme séparateur %2Cce qui donne au final un tableau ne comportant que 3 arbres remarquables à moins de deux kilomètres du point choisi :\n\nx<-GET(\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=arbresremarquablesparis2011&q=&rows=1000&geofilter.distance=48.82670%2C2.38242%2C2000\")\n  y<-fromJSON(rawToChar((x$content)))\n  don<-y$records$fields\ndon <-don%>% select(adresse, libellefrancais, dist, hauteurenm, circonferenceencm)\nkable(don)\n\n\n\n\n\n\n\n\n\n\n\nadresse\nlibellefrancais\ndist\nhauteurenm\ncirconferenceencm\n\n\n\n\nPARC DE BERCY / 128 QUAI DE BERCY\nPlatane\n829.84776688445\n35\n502\n\n\nPARC DE CHOISY / 1 RUE GEORGE EASTMAN\nCèdre\n1699.294305054727\n25\n355\n\n\nJARDIN DE LA GARE DE REUILLY - JULIEN LAUPRETRE / 6 RUE PAUL DUKAS\nLibocèdre\n1728.7655425984415\n20\n205\n\n\n\n\n\n\n\nFonction\nNous pouvons alors créer une petite fonction qui va automatiquement sélectionner les arbres en fonction d’une coordonnée et d’une distance choisies par l’utilisateur :\n\nget_data_geo<-donnees<-function(idtab = \"arbresremarquablesparis2011\",\n                  rows=10,\n                  start=0,\n                  lat = 48.82670,\n                  lon = 2.38242,\n                  dist = 2000) {\n  url<-paste0(\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=\",idtab,\n              \"&q=&rows=\",rows,\n              \"&start=\",start,\n              \"&geofilter.distance=\", lat,\"%2C\", lon,\"%2C\",dist,\n              sep=\"\")\n  \n  x<-GET(url)\n  y<-fromJSON(rawToChar((x$content)))\n  don<-y$records$fields\n  return(don)\n}\n\nNotre fonction est paramétrée par défaut sur la place Paul Ricoeur pour un rayon de 2000 mètres mais on peut ensuite changer les paramètres comme on le souhaite. On peut par exemple rechercher les arbres remarquables dans un rayon de 500 mètres autour de la cathédrale Notre Dame de Paris.\n\ntab<-get_data_geo(idtab = \"arbresremarquablesparis2011\",\n                  rows=1000,\n                  start=0,\n                  lat = 48.85331,\n                  lon = 2.34907,\n                  dist = 500)\nkable(tab)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhauteurenm\ngeom_x_y\ncirconferenceencm\nstadedeveloppement\nremarquable\ngenre\npepiniere\ndateplantation\ntypeemplacement\narrondissement\ncomplementadresse\nidemplacement\nlibellefrancais\ndomanialite\nadresse\nespece\nidbase\ndist\nvarieteoucultivar\n\n\n\n\n19\n48.852783, 2.351016\n210\nAdulte\nOUI\nCorylus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 4E ARRDT\n04-04\n000104001\nNoisetier de Byzance\nJardin\nSQUARE JEAN XXIII / 2 QUAI DE L ARCHEVECHE\ncolurna\n125046\n153.9816687873372\nNA\n\n\n9\n48.852191, 2.347286\n365\nMature\nOUI\nRobinia\nInconnue\n1602-01-01T00:09:21+00:00\nArbre\nPARIS 5E ARRDT\nNA\n000401001\nRobinier\nJardin\nSQUARE RENE VIVIANI MONTEBELLO / 2 RUE DU FOUARRE\npseudoacacia\n124358\n180.29215072419555\nNA\n\n\n10\n48.852102, 2.350804\n167\nAdulte\nOUI\nUlmus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 4E ARRDT\nNA\n000302002\nOrme\nJardin\nSQUARE JEAN XXIII / 2 QUAI DE L ARCHEVECHE\nglabra\n125063\n184.75764884140503\n‘’Pendula’’\n\n\n3\n48.85235, 2.35181\n230\nMature\nOUI\nTamarix\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 4E ARRDT\nNA\n000102002\nTamaris\nJardin\nSQUARE JEAN XXIII / 2 QUAI DE L ARCHEVECHE\nn. sp.\n125051\n226.86413517666327\nNA\n\n\n16\n48.855760, 2.353992\n190\nMature\nOUI\nUlmus\nInconnue\n1700-01-01T00:09:21+00:00\nArbre\nPARIS 4E ARRDT\n04-01\n000301001\nOrme\nAlignement\nPLACE SAINT GERVAIS\nminor\n267663\n451.4910432410224\nNA\n\n\n\n\n\nMais notre fonction peut également marcher pour d’autres tableaux si ceux-ci ont la même structure. On peut ainsi examiner les entreprises localisées à moins de 50 mètres du bâtiment d’Olympe de Gouges à l’aide de la base SIREN et on trouve 11 références :\n\ntab<-get_data_geo(idtab = \"sirene_v3\",\n                  rows=1000,\n                  start=0,\n                  lat = 48.82670,\n                  lon = 2.38242,\n                  dist = 50)\ntab<-tab %>% select(siret,l1_adressage_unitelegale, adresseetablissement,sectionetablissement,naturejuridiqueunitelegale)\nkable(tab)\n\n\n\n\n\n\n\n\n\n\n\nsiret\nl1_adressage_unitelegale\nadresseetablissement\nsectionetablissement\nnaturejuridiqueunitelegale\n\n\n\n\n84261103000011\nELIPS (ETUDIANTS DE LINGUISTIQUE INFORMATIQUE DE PARIS DIDEROT)\n8 PL PAUL RICOEUR\nAutres activites de services\nAssociation déclarée\n\n\n87776849900015\nGEOMIE\nPL PAUL RICOEUR\nAutres activites de services\nAssociation déclarée\n\n\n18750006101539\nCENTRE REGIONAL OEUVRES UNIV SCOLAIRES\n8 PL PAUL RICOEUR\nHebergement et restauration\nAutre établissement public national administratif à compétence territoriale limitée\n\n\n90059716200016\nINGENIEURS SANS FRONTIERES, EQUIPE DE L’UNIVERSITE DE PARIS\n8 PL PAUL RICOEUR\nAutres activites de services\nAssociation déclarée\n\n\n82868797000016\nJUNIOR EIDD CONSEIL\n8 PL PAUL RICOEUR\nActivites specialisees, scientifiques et techniques\nAssociation déclarée\n\n\n78887970800014\nSIMULAUTO\n9 RUE ALBERT EINSTEIN\nEnseignement\nSAS, société par actions simplifiée\n\n\n79378675700013\nPARIS PERMIS\n9 RUE ALBERT EINSTEIN\nEnseignement\nSociété à responsabilité limitée (sans autre indication)\n\n\n87973678300017\nMadame HELENE DUPLANTIER\n7 RUE ALBERT EINSTEIN\nArts, spectacles et activites recreatives\nEntrepreneur individuel\n\n\n84262529500014\nMadame JOANA FONSECA LEITAO\n7 RUE ALBERT EINSTEIN\nActivites de services administratifs et de soutien\nEntrepreneur individuel\n\n\n81325823300028\nCOMPAGNIE LES ENVOLEES\n7 RUE ALBERT EINSTEIN\nArts, spectacles et activites recreatives\nAssociation déclarée\n\n\n88086923500015\nSTREET BIDA\n1 RUE NICOLE REINE LEPAUTE\nHebergement et restauration\nSAS, société par actions simplifiée"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#exercice",
    "href": "11-API-OPENDATASOFT.html#exercice",
    "title": "L’API opendatasoft",
    "section": "Exercice",
    "text": "Exercice\nEssayez de récupérer les informations sur l’ensemble des ventes immobilières de maisons commune de Montcuq-en-Quercy-Blanc (Code Postal 46800) au cours de l’année 2020 puis calculés le prix moyen par m2 de\nbuildingref-france-demande-de-valeurs-foncieres-geolocalisee-millesime\n\n x<-GET(\"https://public.opendatasoft.com/api/records/1.0/search/?dataset=buildingref-france-demande-de-valeurs-foncieres-geolocalisee-millesime&q=montcuq&refine.date_mutation=2020&refine.type_local=Maison&rows=1000\")\n\nw<-rawToChar((x$content))\nd<-fromJSON(w)\nt<-d$records$fields\n\ndon<-t %>% select(surface_reelle_bati,surface_terrain,valeur_fonciere) %>% \n  mutate(prixm2 = valeur_fonciere/surface_reelle_bati)\n\nkable(don)\n\n\n\n\nsurface_reelle_bati\nsurface_terrain\nvaleur_fonciere\nprixm2\n\n\n\n\n60\n1258\n60000\n1000.0000\n\n\n140\n1205\n160000\n1142.8571\n\n\n100\n932\n150000\n1500.0000\n\n\n102\n910\n238000\n2333.3333\n\n\n50\n800\n121000\n2420.0000\n\n\n159\n367\n330000\n2075.4717\n\n\n50\n443\n190150\n3803.0000\n\n\n137\n5566\n165000\n1204.3796\n\n\n100\n51\n45000\n450.0000\n\n\n280\n450\n270000\n964.2857\n\n\n81\n1579\n146000\n1802.4691\n\n\n148\n425\n278000\n1878.3784\n\n\n71\n71\n110000\n1549.2958\n\n\n70\n137\n41800\n597.1429\n\n\n148\n100\n278000\n1878.3784\n\n\n99\n500\n225000\n2272.7273\n\n\n99\n2460\n225000\n2272.7273\n\n\n140\n1118\n370000\n2642.8571\n\n\n140\n610\n370000\n2642.8571\n\n\n77\n739\n107000\n1389.6104\n\n\n134\n365\n130000\n970.1493\n\n\n64\n957\n103000\n1609.3750\n\n\n55\n38\n217250\n3950.0000\n\n\n100\n500\n150000\n1500.0000\n\n\n200\n1060\n225000\n1125.0000\n\n\n75\n1827\n106177\n1415.6933\n\n\n27\n1275\n187000\n6925.9259\n\n\n150\n327\n300000\n2000.0000\n\n\n163\n225\n222000\n1361.9632\n\n\n70\n358\n82000\n1171.4286\n\n\n20\n31\n41800\n2090.0000\n\n\n79\n1275\n187000\n2367.0886\n\n\n95\n71\n217250\n2286.8421\n\n\n324\n234\n510000\n1574.0741\n\n\n220\n1210\n335000\n1522.7273\n\n\n40\nNA\n18000\n450.0000\n\n\n140\n2080\n370000\n2642.8571\n\n\n210\n170\n535240\n2548.7619\n\n\n70\n271\n82000\n1171.4286\n\n\n\n\nsummary(don)\n\n surface_reelle_bati surface_terrain  valeur_fonciere      prixm2    \n Min.   : 20.0       Min.   :  31.0   Min.   : 18000   Min.   : 450  \n 1st Qu.: 70.0       1st Qu.: 243.2   1st Qu.:108500   1st Qu.:1188  \n Median :100.0       Median : 500.0   Median :187000   Median :1609  \n Mean   :115.1       Mean   : 842.0   Mean   :202530   Mean   :1910  \n 3rd Qu.:144.0       3rd Qu.:1183.2   3rd Qu.:274000   3rd Qu.:2310  \n Max.   :324.0       Max.   :5566.0   Max.   :535240   Max.   :6926  \n                     NA's   :1                                       \n\nplot(don$surface_reelle_bati,don$valeur_fonciere)"
  },
  {
    "objectID": "12-API-INSEE.html",
    "href": "12-API-INSEE.html",
    "title": "L’API INSEE",
    "section": "",
    "text": "L’utilisation d’API à l’aide des fonctions de base httpr et jsonlite constitue à moyen terme une étape indispensable de la formation d’un data analyste. Mais heureusement elle n’est pas toujours indispensable pour le débutant car plusieurs packages R (ou Python) ont été développées par des programmeurs pour faciliter l’usage des API.\nCes packages executent en pratique les commandes de l’API, mais sans que l’utilisateur ait besoin d’avoir aucune connaissance sur la syntaxe de la fonction GET() qui a collecté les données ni des transformations effectuées sur les résultats pour transformer les données JSON en data.frame ou tibble. La connaissance de ces packages spécialisées offre donc une grosse économie de temps … s’ils ont été bien conçus.\nOn va prendre comme exemple le package insee mis au point récemment pour faciliter l’accès aux données de cette organisation. La documentation du package est accessible par le lien ci-dessous\nhttps://pyr-opendatafr.github.io/R-Insee-Data/articles/insee.html"
  },
  {
    "objectID": "12-API-INSEE.html#mode-demploi",
    "href": "12-API-INSEE.html#mode-demploi",
    "title": "L’API INSEE",
    "section": "Mode d’emploi",
    "text": "Mode d’emploi\nOn commence par installer le package insee ce qui peut prendre quelques minutes mais sera fait une seule fois (sauf mise à jour).\n\n### Normal version\n# install.packages(\"insee\")\n\n### Development version\n# devtools::install_github(\"InseeFr/R-Insee-Data\")\n\nOn peut ensuite lancer le package pour l’utiliser avec library() et on ajoute le package tidyverse que l’INSEE semble privilégier pour l’exploitation des données :\n\nlibrary(insee)\nlibrary(tidyverse,warn.conflicts = F)\nlibrary(knitr)\n\n\nChargement de la liste des tableaux\nOn commence par télécharger le catalogue des tableaux de données disponibles,à l’aide de la commande get_dataset_list()\n\ncatalogue = get_dataset_list()\nkable(head(catalogue))\n\n\n\n\n\n\n\n\n\n\n\nid\nName.fr\nName.en\nurl\nn_series\n\n\n\n\nBALANCE-PAIEMENTS\nBalance des paiements\nBalance of payments\nhttps://www.insee.fr/fr/statistiques/series/103212755\n197\n\n\nCHOMAGE-TRIM-NATIONAL\nChômage, taux de chômage par sexe et âge (sens BIT)\nUnemployment, unemployment rate and halo by sex and age (ILO)\nhttps://www.insee.fr/fr/statistiques/series/103167923\n169\n\n\nCLIMAT-AFFAIRES\nIndicateurs synthétiques du climat des affaires\nBusiness climate composite indicators\nhttps://www.insee.fr/fr/statistiques/series/103047029\n3\n\n\nCNA-2010-CONSO-MEN\nConsommation des ménages - Résultats par produit, fonction et durabilité\nHouseholds’ consumption - Results by product, function and durability\nhttps://www.insee.fr/fr/statistiques/series/102331845\n2247\n\n\nCNA-2010-CONSO-SI\nDépenses de consommation finale par secteur institutionnel - Résultats par opération et produit\nFinal consumption expenditure by institutional sectors - Results by transaction and product\nhttps://www.insee.fr/fr/statistiques/series/102809534\n1391\n\n\nCNA-2010-CPEB\nComptes de production et d’exploitation par branche\nProduction and operating accounts by branch\nhttps://www.insee.fr/fr/statistiques/series/102852781\n2739\n\n\n\n\n\nChaque tableau comporte un très grand nombre de séries chronologiques parmi lesquelles il faut opérer un choix afin d’extraire exactement ce que l’on veut.\n\n\nExamen des séries présentes dans un tableau\nUne fois que l’on a choisi un tableau, on peut examiner plus en détail les différentes séries qui y sont présentes à l’aide de la commande get_idbank_list(). On va par exemple examiner le contenu de la base de données “DECES-MORTALITE” :\n\nvar<-get_idbank_list(\"DECES-MORTALITE\") \nstr(var)\n\nFALSE tibble [1,905 × 33] (S3: tbl_df/tbl/data.frame)\nFALSE  $ nomflow               : chr [1:1905] \"DECES-MORTALITE\" \"DECES-MORTALITE\" \"DECES-MORTALITE\" \"DECES-MORTALITE\" ...\nFALSE  $ idbank                : chr [1:1905] \"000067679\" \"000067680\" \"000067681\" \"000436394\" ...\nFALSE  $ cleFlow               : chr [1:1905] \"A.NOMBRE_DECES.VALEUR_ABSOLUE.DECES.FM.0.SO.INDIVIDUS.BRUT.FALSE\" \"A.TAUX_MORTALITE.TAUX.TXMOR.FM.0.SO.DECES_1000_PERS.BRUT.FALSE\" \"A.TAUX_MORTALITE.TAUX.TXMORINF.FM.0.SO.P1000.BRUT.FALSE\" \"M.NOMBRE_DECES.VALEUR_ABSOLUE.DECES.FM.0.SO.INDIVIDUS.BRUT.FALSE\" ...\nFALSE  $ FREQ                  : chr [1:1905] \"A\" \"A\" \"A\" \"M\" ...\nFALSE  $ INDICATEUR            : chr [1:1905] \"NOMBRE_DECES\" \"TAUX_MORTALITE\" \"TAUX_MORTALITE\" \"NOMBRE_DECES\" ...\nFALSE  $ NATURE                : chr [1:1905] \"VALEUR_ABSOLUE\" \"TAUX\" \"TAUX\" \"VALEUR_ABSOLUE\" ...\nFALSE  $ DEMOGRAPHIE           : chr [1:1905] \"DECES\" \"TXMOR\" \"TXMORINF\" \"DECES\" ...\nFALSE  $ REF_AREA              : chr [1:1905] \"FM\" \"FM\" \"FM\" \"FM\" ...\nFALSE  $ SEXE                  : chr [1:1905] \"0\" \"0\" \"0\" \"0\" ...\nFALSE  $ AGE                   : chr [1:1905] \"SO\" \"SO\" \"SO\" \"SO\" ...\nFALSE  $ UNIT_MEASURE          : chr [1:1905] \"INDIVIDUS\" \"DECES_1000_PERS\" \"P1000\" \"INDIVIDUS\" ...\nFALSE  $ CORRECTION            : chr [1:1905] \"BRUT\" \"BRUT\" \"BRUT\" \"BRUT\" ...\nFALSE  $ SERIE_ARRETEE         : chr [1:1905] \"FALSE\" \"FALSE\" \"FALSE\" \"FALSE\" ...\nFALSE  $ FREQ_label_fr         : chr [1:1905] \"Annuelle\" \"Annuelle\" \"Annuelle\" \"Mensuelle\" ...\nFALSE  $ FREQ_label_en         : chr [1:1905] \"Annual\" \"Annual\" \"Annual\" \"Monthly\" ...\nFALSE  $ INDICATEUR_label_fr   : chr [1:1905] \"Nombre de décès\" \"Taux de mortalité\" \"Taux de mortalité\" \"Nombre de décès\" ...\nFALSE  $ INDICATEUR_label_en   : chr [1:1905] \"Number of dead\" \"Mortality rate\" \"Mortality rate\" \"Number of dead\" ...\nFALSE  $ NATURE_label_fr       : chr [1:1905] \"Valeur absolue\" \"Taux\" \"Taux\" \"Valeur absolue\" ...\nFALSE  $ NATURE_label_en       : chr [1:1905] \"Absolute value\" \"Rate\" \"Rate\" \"Absolute value\" ...\nFALSE  $ DEMOGRAPHIE_label_fr  : chr [1:1905] \"Décès de tous âges\" \"Taux de mortalité\" \"Taux de mortalité infantile\" \"Décès de tous âges\" ...\nFALSE  $ DEMOGRAPHIE_label_en  : chr [1:1905] \"Deaths of all ages\" \"Mortality rate\" \"Infant mortality rate\" \"Deaths of all ages\" ...\nFALSE  $ REF_AREA_label_fr     : chr [1:1905] \"France métropolitaine\" \"France métropolitaine\" \"France métropolitaine\" \"France métropolitaine\" ...\nFALSE  $ REF_AREA_label_en     : chr [1:1905] \"Metropolitan France\" \"Metropolitan France\" \"Metropolitan France\" \"Metropolitan France\" ...\nFALSE  $ SEXE_label_fr         : chr [1:1905] \"Ensemble\" \"Ensemble\" \"Ensemble\" \"Ensemble\" ...\nFALSE  $ SEXE_label_en         : chr [1:1905] \"All\" \"All\" \"All\" \"All\" ...\nFALSE  $ AGE_label_fr          : chr [1:1905] \"Sans objet\" \"Sans objet\" \"Sans objet\" \"Sans objet\" ...\nFALSE  $ AGE_label_en          : chr [1:1905] \"Not applicable\" \"Not applicable\" \"Not applicable\" \"Not applicable\" ...\nFALSE  $ UNIT_MEASURE_label_fr : chr [1:1905] \"individus\" \"nombre de décès pour 1 000 personnes\" \"pour mille\" \"individus\" ...\nFALSE  $ UNIT_MEASURE_label_en : chr [1:1905] \"individuals\" \"number of deaths per 1,000 inhabitants\" \"per thousand\" \"individuals\" ...\nFALSE  $ CORRECTION_label_fr   : chr [1:1905] \"Non corrigé\" \"Non corrigé\" \"Non corrigé\" \"Non corrigé\" ...\nFALSE  $ CORRECTION_label_en   : chr [1:1905] \"Uncorrected\" \"Uncorrected\" \"Uncorrected\" \"Uncorrected\" ...\nFALSE  $ SERIE_ARRETEE_label_fr: chr [1:1905] \"non\" \"non\" \"non\" \"non\" ...\nFALSE  $ SERIE_ARRETEE_label_en: chr [1:1905] \"nO\" \"nO\" \"nO\" \"nO\" ...\n\n\nLe résultat est un tibble comportant 1905 lignes et 39 colonnes. Il correspond en pratique aux 1905 séries chronologiques que l’on peut extraire de la base de données. Chaque série dispose d’un code unique contenu dans la variable idbank.\n\n\nExtraction d’une série à l’aide de son identifiant\nUne première solution pour extraire une série consiste à parcourir le tableau des variables jusqu’à repérer la ligne qui nous intéresse puis à noter son idbank et à extraire la série correspondante à l’aide de la fonction get_insee_idbank(). Par exemple, la première ligne du tableau des variables dont le code est “000436398” va renvoyer un tableau du taux brut de mortalité infantile en France métropolitaine de Janvier 1975 à Décembre 2014. On peut en faire rapidement un graphique avec la fonction plot() de R-Base\n\ndon<-get_insee_idbank(\"000436398\")\n\nFALSE \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ndon<-don[order(don$DATE),1:3]\nplot(don$DATE,don$OBS_VALUE, \n     type =\"l\", \n     col=\"red\", \n     ylab = \"Décès 0-1 ans pour  1000 naissances\",\n     xlab = \"Données mensuelles\",\n     main = \"Evolution de la mortalité infantile en France (1975-2014)\",\n     sub = \"Source : Insee\")\n\n\n\n\nOn remarque que la courbe a des oscillations saisonnières beaucoup moins fortes après 1995 ce qui est sans doute lié à un changement dans le mode de collecte des données plutôt qu’à la réalité.\nOn note aussi que les données s’arrêtent en 2014 ce qui est bizarre puisque l’API devrait nous donner les chiffres les plus récents. en fait les données plus récentes sont disponibles mais elles font partie d’une autre série de données.\n\n\nExtraction d’un ensemble de séries d’un même tableau\nSupposons que l’on veuille extraire trois courbes décrivant l’espérance de vie des hommes en France métropolitaine, à 20, 40 et 60 ans. Nous lançons alors une requête pour ne retenir dans le tableau des variables que les lignes qui nous intéressent.\n\nsel  = \n  get_idbank_list(\"DECES-MORTALITE\") %>% \n  filter(SEXE == \"1\") %>%\n  filter(FREQ == \"A\") %>% #données annuelles\n  filter(REF_AREA == \"FM\") %>% #France métropolitaine\n  filter(DEMOGRAPHIE %in% c(\"ESPV-20\",\"ESPV-40\",\"ESPV-60\")) # Espérance de vie\n\nkable(head(sel))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnomflow\nidbank\ncleFlow\nFREQ\nINDICATEUR\nNATURE\nDEMOGRAPHIE\nREF_AREA\nSEXE\nAGE\nUNIT_MEASURE\nCORRECTION\nSERIE_ARRETEE\nFREQ_label_fr\nFREQ_label_en\nINDICATEUR_label_fr\nINDICATEUR_label_en\nNATURE_label_fr\nNATURE_label_en\nDEMOGRAPHIE_label_fr\nDEMOGRAPHIE_label_en\nREF_AREA_label_fr\nREF_AREA_label_en\nSEXE_label_fr\nSEXE_label_en\nAGE_label_fr\nAGE_label_en\nUNIT_MEASURE_label_fr\nUNIT_MEASURE_label_en\nCORRECTION_label_fr\nCORRECTION_label_en\nSERIE_ARRETEE_label_fr\nSERIE_ARRETEE_label_en\n\n\n\n\nDECES-MORTALITE\n001686948\nA.ESPERANCE_VIE.VALEUR_ABSOLUE.ESPV-20.FM.1.SO.ANNEES.BRUT.FALSE\nA\nESPERANCE_VIE\nVALEUR_ABSOLUE\nESPV-20\nFM\n1\nSO\nANNEES\nBRUT\nFALSE\nAnnuelle\nAnnual\nEspérance de vie\nLife expectancy\nValeur absolue\nAbsolute value\nEspérance de vie à 20 ans\nLife expectancy at 20 years\nFrance métropolitaine\nMetropolitan France\nHommes\nMen\nSans objet\nNot applicable\nnombre d’années\nnumber of years\nNon corrigé\nUncorrected\nnon\nnO\n\n\nDECES-MORTALITE\n001686949\nA.ESPERANCE_VIE.VALEUR_ABSOLUE.ESPV-40.FM.1.SO.ANNEES.BRUT.FALSE\nA\nESPERANCE_VIE\nVALEUR_ABSOLUE\nESPV-40\nFM\n1\nSO\nANNEES\nBRUT\nFALSE\nAnnuelle\nAnnual\nEspérance de vie\nLife expectancy\nValeur absolue\nAbsolute value\nEspérance de vie à 40 ans\nLife expectancy at 40 years\nFrance métropolitaine\nMetropolitan France\nHommes\nMen\nSans objet\nNot applicable\nnombre d’années\nnumber of years\nNon corrigé\nUncorrected\nnon\nnO\n\n\nDECES-MORTALITE\n001686950\nA.ESPERANCE_VIE.VALEUR_ABSOLUE.ESPV-60.FM.1.SO.ANNEES.BRUT.FALSE\nA\nESPERANCE_VIE\nVALEUR_ABSOLUE\nESPV-60\nFM\n1\nSO\nANNEES\nBRUT\nFALSE\nAnnuelle\nAnnual\nEspérance de vie\nLife expectancy\nValeur absolue\nAbsolute value\nEspérance de vie à 60 ans\nLife expectancy at 60 years\nFrance métropolitaine\nMetropolitan France\nHommes\nMen\nSans objet\nNot applicable\nnombre d’années\nnumber of years\nNon corrigé\nUncorrected\nnon\nnO\n\n\nDECES-MORTALITE\n010536470\nA.ESPERANCE_VIE.VALEUR_ABSOLUE.ESPV-20.FM.1.SO.ANNEES.BRUT.FALSE\nA\nESPERANCE_VIE\nVALEUR_ABSOLUE\nESPV-20\nFM\n1\nSO\nANNEES\nBRUT\nFALSE\nAnnuelle\nAnnual\nEspérance de vie\nLife expectancy\nValeur absolue\nAbsolute value\nEspérance de vie à 20 ans\nLife expectancy at 20 years\nFrance métropolitaine\nMetropolitan France\nHommes\nMen\nSans objet\nNot applicable\nnombre d’années\nnumber of years\nNon corrigé\nUncorrected\nnon\nnO\n\n\nDECES-MORTALITE\n010536474\nA.ESPERANCE_VIE.VALEUR_ABSOLUE.ESPV-40.FM.1.SO.ANNEES.BRUT.FALSE\nA\nESPERANCE_VIE\nVALEUR_ABSOLUE\nESPV-40\nFM\n1\nSO\nANNEES\nBRUT\nFALSE\nAnnuelle\nAnnual\nEspérance de vie\nLife expectancy\nValeur absolue\nAbsolute value\nEspérance de vie à 40 ans\nLife expectancy at 40 years\nFrance métropolitaine\nMetropolitan France\nHommes\nMen\nSans objet\nNot applicable\nnombre d’années\nnumber of years\nNon corrigé\nUncorrected\nnon\nnO\n\n\nDECES-MORTALITE\n010536478\nA.ESPERANCE_VIE.VALEUR_ABSOLUE.ESPV-60.FM.1.SO.ANNEES.BRUT.FALSE\nA\nESPERANCE_VIE\nVALEUR_ABSOLUE\nESPV-60\nFM\n1\nSO\nANNEES\nBRUT\nFALSE\nAnnuelle\nAnnual\nEspérance de vie\nLife expectancy\nValeur absolue\nAbsolute value\nEspérance de vie à 60 ans\nLife expectancy at 60 years\nFrance métropolitaine\nMetropolitan France\nHommes\nMen\nSans objet\nNot applicable\nnombre d’années\nnumber of years\nNon corrigé\nUncorrected\nnon\nnO\n\n\n\n\n\nOn découvre que le programme renvoie 6 lignes au lieu de 3. Pourquoi ? Parce que l’INSEE stocke différemment des séries anciennes et des séries récentes. Il faut donc effectuer une requête sur les 4 codes à la fois pour avoir la série la plus longue.\n\n\nRecupération et nettoyage des données\nOn récupère les données puis on procède à un petit nettoyage du tableau pour ne conserver que les colonnes utiles.\n\ndon = get_insee_idbank(sel$idbank)\n\nFALSE \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |======================================================================| 100%\n\ndon2<-don %>% select(ANNEE = DATE, ESPVIE= OBS_VALUE, AGE = TITLE_FR) %>% \n              mutate(AGE = as.factor(AGE)) %>% \n              arrange(AGE, ANNEE)\nlevels(don2$AGE) <- c(\"20 ans\", \"40 ans\",\"60 ans\")\nkable(head(don2))\n\n\n\n\nANNEE\nESPVIE\nAGE\n\n\n\n\n1946-01-01\n48.0\n20 ans\n\n\n1947-01-01\n48.4\n20 ans\n\n\n1948-01-01\n48.5\n20 ans\n\n\n1949-01-01\n48.2\n20 ans\n\n\n1950-01-01\n48.7\n20 ans\n\n\n1951-01-01\n48.2\n20 ans\n\n\n\n\n\n\n\nConstruction d’un graphique\nOn peut maintenant construire notre graphique à l’aide par exemple de ggplot2 :\n\np<-ggplot(don2) + \n   aes(x=ANNEE,y=ESPVIE, color = AGE) +\n    geom_line() +\n    ggtitle(label= \"Espérance de vie en France Métropolitaine\",\n            subtitle = \"Source : INSEE\")+\n    scale_x_date(\"Données annuelles\") +\n    scale_y_continuous(\"Années de vie restantes\",limits = c(0,NA))\np\n\n\n\n\n\n\nDiscussion\nComme on peut le voir, l’utilisation d’un package simplifie l’usage des API mais ne dispense pas d’un apprentissage souvent long pour comprendre toutes les finesses du package (et parfois ses bugs …). Dans le cas du package INSEE, l’utilisation s’avère assez lourde mais permet d’accéder à un nombre considérable de données !"
  },
  {
    "objectID": "12-API-INSEE.html#exercices",
    "href": "12-API-INSEE.html#exercices",
    "title": "L’API INSEE",
    "section": "Exercices",
    "text": "Exercices\n\nExercice 1 : utilisation du package ‘insee’\nConstruire à l’aide du package INSEE un graphique de l’évolution mensuelle de l’espérance de vie des femmes à la naissance en France Métropolitaine de 1945 à 2023.\n\n\nFALSE \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "20-CARTO-INTRO.html",
    "href": "20-CARTO-INTRO.html",
    "title": "CARTO-Intro",
    "section": "",
    "text": "La représentation cartographiques de données spatiales dans R s’est beucoup développée depuis quelques années et on dispose désormais de packages de très bonne qualité pour réaliser des cartes statiques destyinées à la publication ou des cartes dynamiques destinées aux interfaces web.\nDans le cadre de ce cours, on se limitera à la présentation de trois questions, chacune associée à la maîtrise d’un package :\n\nAcquisition de données spatiales et mise en forme (sf)\nCartographie statique pour l’édition (mapsf)\nCartographie dynamique pour le web (mapview)"
  },
  {
    "objectID": "21-CARTO-sf.html",
    "href": "21-CARTO-sf.html",
    "title": "CARTO-sf",
    "section": "",
    "text": "# packages utilitaires\nlibrary(knitr)\nlibrary(dplyr)\n\n\nAttachement du package : 'dplyr'\n\n\nLes objets suivants sont masqués depuis 'package:stats':\n\n    filter, lag\n\n\nLes objets suivants sont masqués depuis 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(jsonlite)\n\n# Data packages\nlibrary(wbstats)\n\nWarning: le package 'wbstats' a été compilé avec la version R 4.2.2\n\nlibrary(rnaturalearth)\n\nWarning: le package 'rnaturalearth' a été compilé avec la version R 4.2.2\n\n# Packages cartographiques\nlibrary(sf)\n\nLinking to GEOS 3.9.1, GDAL 3.4.3, PROJ 7.2.1; sf_use_s2() is TRUE\n\nlibrary(geojsonsf)\nlibrary(mapsf)\nL’importation et l’exportation de données spatiales peut se faire de différentes manières qui sont illustrées dans trois exemples. L’important est d’aboutir à un fichier de type sf (spatial features) combinant les données géométriques et les données statistiques dans un seul objet. Une fois créé, cet obet sera stocké au format interne de R (.RDS)."
  },
  {
    "objectID": "21-CARTO-sf.html#importation-dun-shapefile",
    "href": "21-CARTO-sf.html#importation-dun-shapefile",
    "title": "CARTO-sf",
    "section": "Importation d’un shapefile",
    "text": "Importation d’un shapefile\n\nCarte au format shapefile\nBeaucoup de fonds de cartes sont stockés au format shapefile, utilisé dans les systèmes d’information géographiques (SIG). Un shapefile se compose en réalité de trois ou quatre fichiers correspondant la géométrie (fic.shp), à la projection (fic.prj), aux données attributaires (fic.dbf), etc..\nOn charge le fonds de carte au format shapefile avec la fonction st_read() du package sf. On ne lui indique que le nom du fichier de géométrie et il lit automatiquement les autres.\n\nmap<-st_read(\"carto/europe88/euro1988_map.shp\")\n\nReading layer `euro1988_map' from data source \n  `C:\\git\\datamining2023\\carto\\europe88\\euro1988_map.shp' using driver `ESRI Shapefile'\nSimple feature collection with 25 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 680158.7 ymin: 576113.9 xmax: 5609069 ymax: 4991631\nProjected CRS: ETRS89-extended / LCC Europe\n\n\nLe fichier est au format sf qui est le format cartographique de R. Il comporte une colonne spéciale appelée geometry.\n\nclass(map)\n\n[1] \"sf\"         \"data.frame\"\n\nhead(map)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 3496766 ymin: 1525952 xmax: 5448053 ymax: 2758691\nProjected CRS: ETRS89-extended / LCC Europe\n  ISO3                       geometry\n1  ALB MULTIPOLYGON (((4777759 184...\n2  AUT MULTIPOLYGON (((4494160 246...\n3  BEL MULTIPOLYGON (((3728385 267...\n4  BGR MULTIPOLYGON (((5260441 208...\n5  CHE MULTIPOLYGON (((3968843 232...\n6  CSK MULTIPOLYGON (((4327916 268...\n\n\nOn peut visualiser la carte enb effectuant un plot de la colonne geometry :\n\nplot(map$geometry)\n\n\n\n\n\n\nDonnées au format .csv\n\ndon<-read.table(\"carto/europe88/euro1988.csv\",\n                sep=\";\",\n                header=T,\n                encoding = \"UTF-8\")\nclass(don)\n\n[1] \"data.frame\"\n\nhead(don)\n\n  PAYS BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n1  ALB  Soc   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115 1684833\n2  AUT  Cap 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715 2335579\n3  BEL  Cap  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312 2667243\n4  BGR  Soc  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070 1930219\n5  CHE  Cap 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378 2243130\n6  CSK  Soc  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005 2540281\n\n\n\n\nJointure\n\nmapdon<-merge(map,don,by.x=\"ISO3\",by.y=\"PAYS\",all.x=T,all.y=T)\nclass(mapdon)\n\n[1] \"sf\"         \"data.frame\"\n\nhead(mapdon)\n\nSimple feature collection with 6 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 3496766 ymin: 1525952 xmax: 5448053 ymax: 2758691\nProjected CRS: ETRS89-extended / LCC Europe\n  ISO3 BLOC   PNB  TMI ESP URB NAT MOR FEC JEU VIE SUP  POP       X       Y\n1  ALB  Soc   600 43.0  71  34  27   6 3.3  35   5  29  3.1 4825115 1684833\n2  AUT  Cap 10000 10.3  75  55  12  12 1.4  18  14  84  7.6 4299715 2335579\n3  BEL  Cap  9200  9.7  75  95  12  11 1.5  19  14  31  9.9 3636312 2667243\n4  BGR  Soc  2000 14.5  72  65  13  11 2.0  21  11 111  9.0 5206070 1930219\n5  CHE  Cap 17800  6.8  77  61  12   9 1.5  17  14  41  6.6 3869378 2243130\n6  CSK  Soc  3200 13.9  71  74  14  12 2.0  24  11 128 15.6 4487005 2540281\n                        geometry\n1 MULTIPOLYGON (((4777759 184...\n2 MULTIPOLYGON (((4494160 246...\n3 MULTIPOLYGON (((3728385 267...\n4 MULTIPOLYGON (((5260441 208...\n5 MULTIPOLYGON (((3968843 232...\n6 MULTIPOLYGON (((4327916 268...\n\n\n\n\nEssai de cartographie\n\nplot(mapdon[\"PNB\"])\n\n\n\n\n\n\nSauvegarde du fichier sf\n\nsaveRDS(mapdon,\"carto/europe88/europe88_sf.RDS\")"
  },
  {
    "objectID": "21-CARTO-sf.html#importation-à-laide-de-packages",
    "href": "21-CARTO-sf.html#importation-à-laide-de-packages",
    "title": "CARTO-sf",
    "section": "Importation à l’aide de packages",
    "text": "Importation à l’aide de packages\nNous allons essayer de constituer une carte des émissions de CO2 par habitant des pays d’Afrique en 2018 basée sur la combinaison des données wbstats et du fonds de carte naturalearth.\n\nImportation du fonds de carte\nOn charge le fonds de carte countries110du package rnaturalearth et on en extrait les pays africains ainsi que deux ou trois variables utiles. On utilise la commande st_as_sf()pour passer le fonds de carte du format sp (ancien) au format sf (actuel).\n\nlibrary(rnaturalearth)\nmap_world<-(countries110) %>% st_as_sf()\nmap<- map_world %>% filter(continent == \"Africa\") %>%\n          select(iso3=iso_a3,name, subregion)\nkable(head(map))\n\n\n\n\n\n\n\n\n\n\niso3\nname\nsubregion\ngeometry\n\n\n\n\nAGO\nAngola\nMiddle Africa\nMULTIPOLYGON (((16.32653 -5…\n\n\nBDI\nBurundi\nEastern Africa\nMULTIPOLYGON (((29.34 -4.49…\n\n\nBEN\nBenin\nWestern Africa\nMULTIPOLYGON (((2.691702 6….\n\n\nBFA\nBurkina Faso\nWestern Africa\nMULTIPOLYGON (((-2.827496 9…\n\n\nBWA\nBotswana\nSouthern Africa\nMULTIPOLYGON (((25.64916 -1…\n\n\nCAF\nCentral African Rep.\nMiddle Africa\nMULTIPOLYGON (((15.27946 7….\n\n\n\n\nclass(map)\n\n[1] \"sf\"         \"data.frame\"\n\n\n\n\nProjection\nNotre carte n’est pas projetée actuellement (les coordonnées sont en latitude et longitude). On modifie son “Coordinate Reference System” pour obtenir des coordonnées planes permettant de calculer des distances.\n\nmap<-st_transform(map,crs = 32631)\nplot(map$geometry)\n\n\n\n\n\n\nImportation des données statistiques\nOn importe les données statistiques correspondant aux pays qui ont été retenus dans le fonds de carte.\n\nmycountries<-map$iso3\ndf   <- wb_data(indicator  = c(\"SP.POP.TOTL\", \"EN.ATM.CO2E.KT\"),\n                return_wide = TRUE,\n                start_date = 2018,\n                end_date = 2018,\n                country = mycountries)\n\nWarning in format_wb_country(country, cache = cache): The following country\nvalues are not valid and are being excluded from the request: ESH,NA\n\nkable(head(df))\n\n\n\n\n\n\n\n\n\n\n\n\niso2c\niso3c\ncountry\ndate\nEN.ATM.CO2E.KT\nSP.POP.TOTL\n\n\n\n\nAO\nAGO\nAngola\n2018\n23960\n31273533\n\n\nBI\nBDI\nBurundi\n2018\n690\n11493472\n\n\nBJ\nBEN\nBenin\n2018\n7420\n11940683\n\n\nBF\nBFA\nBurkina Faso\n2018\n4670\n20392723\n\n\nBW\nBWA\nBotswana\n2018\n7310\n2451409\n\n\nCF\nCAF\nCentral African Republic\n2018\n230\n5094780\n\n\n\n\n\nNous renommons les variables pour avoir un tableau plus simple ou la population est en millions d’habitants, les émissions de CO2 en millions de tonnes. On y ajoute l’intensité des émissions en tonnes par habitant.\n\ndon <-df %>% select(iso3 = iso3c,  POP = SP.POP.TOTL, CO2 = EN.ATM.CO2E.KT) %>%\n            mutate(POP = POP/1000000, CO2 = CO2/1000, CO2_hab = CO2/POP)\nkable(head(don),digits = 2)\n\n\n\n\niso3\nPOP\nCO2\nCO2_hab\n\n\n\n\nAGO\n31.27\n23.96\n0.77\n\n\nBDI\n11.49\n0.69\n0.06\n\n\nBEN\n11.94\n7.42\n0.62\n\n\nBFA\n20.39\n4.67\n0.23\n\n\nBWA\n2.45\n7.31\n2.98\n\n\nCAF\n5.09\n0.23\n0.05\n\n\n\n\n\n\n\nJointure\nPuisque les fichiers comportent un même identifiant et un seul, on peut effectuer la jointure avec la fonction left_join() du package dplyr.\n\nmapdon <- left_join(map,don) %>% st_as_sf()\n\nJoining, by = \"iso3\"\n\nkable(head(mapdon))\n\n\n\n\n\n\n\n\n\n\n\n\n\niso3\nname\nsubregion\nPOP\nCO2\nCO2_hab\ngeometry\n\n\n\n\nAGO\nAngola\nMiddle Africa\n31.273533\n23.96\n0.7661430\nMULTIPOLYGON (((1988450 -66…\n\n\nBDI\nBurundi\nEastern Africa\n11.493472\n0.69\n0.0600341\nMULTIPOLYGON (((3530045 -55…\n\n\nBEN\nBenin\nWestern Africa\n11.940683\n7.42\n0.6214050\nMULTIPOLYGON (((465897.1 69…\n\n\nBFA\nBurkina Faso\nWestern Africa\n20.392723\n4.67\n0.2290033\nMULTIPOLYGON (((-140403.2 1…\n\n\nBWA\nBotswana\nSouthern Africa\n2.451409\n7.31\n2.9819585\nMULTIPOLYGON (((2941565 -22…\n\n\nCAF\nCentral African Rep.\nMiddle Africa\n5.094780\n0.23\n0.0451442\nMULTIPOLYGON (((1865230 839…\n\n\n\n\n\n\n\nEssai de cartographie\nOn réalise ici une belle carte avec le package mapsf qui sera expliqué plus loin\n\nlibrary(mapsf)\nmf_theme(\"agolalight\")\nmapdon %>% \n  mf_map(\"CO2_hab\", \n         \"choro\",\n         breaks=\"jenks\",\n         leg_pos=\"bottomleft\",\n         leg_title = \"en tonnes/hab.\")%>%\n  mf_map(\"CO2\", \n         inches = 0.2,\n         \"prop\",\n         col=\"red\",\n         leg_pos = \"topleft\",\n         leg_title = \"en millions de tonnes\")\nmf_title(\"Emissions de CO2 des pays d''Afrique en 2018\")\n\n\n\n\n\n\nSauvegarde du fichier sf\n\nsaveRDS(mapdon,\"carto/africa/africa_sf.RDS\")"
  },
  {
    "objectID": "21-CARTO-sf.html#importation-au-format-geojson",
    "href": "21-CARTO-sf.html#importation-au-format-geojson",
    "title": "CARTO-sf",
    "section": "Importation au format GEOJSON",
    "text": "Importation au format GEOJSON\nLa plupart des API permettent de récupérer directement des fichiers combinant les données statistiques et cartographiques au format GEOJSON. Il suffit alors de les convertir au format sf en une seule opération, sans avoir besoin d’effectuer de jointure.\n\nRécupération d’un fichier GEOJSON\nOn commence par repérer une url permettant de récupérer un fichier de type GeoJSON. Puis on récupère le fichier et on l’enregistre à l’aide de la fonction dowload.file() en lui donnat l’extension .geojson. Ce fichier pourra être utilisé dans d’autres langages de programmation comme Python.\n\nmyurl<- \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/georef-france-commune/exports/geojson?lang=fr&refine=reg_name%3A%22%C3%8Ele-de-France%22&timezone=Europe%2FBerlin\"\n\n\n\ndownload.file(url=myurl,\n              destfile=\"carto/idfcom/idfcom.geojson\", \n              method=\"curl\")\n\n\n\nConversion du fichier geojson au format sf\nOn convertit le fichier geojson au format sf à l’aide de la fonction geojson_sf()du package geojsonsf. On vérifie que le fichier est bien de la bonne classe\n\nmapdon<-geojson_sf(\"carto/idfcom/idfcom.geojson\")\nclass(mapdon)\n\n[1] \"sf\"         \"data.frame\"\n\n\n\n\nSélection des variables\nOn ne conserve que la colonne code et on ajoute une colonne département\n\nmapdon<-mapdon %>% select(com_code) %>% \n  mutate(com_code = substr(com_code,3,7),\n         depcode = substr(com_code,1,2))\nhead(mapdon)\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2.584831 ymin: 48.49468 xmax: 3.48622 ymax: 48.91068\nGeodetic CRS:  WGS 84\n  com_code                       geometry depcode\n1    77072 POLYGON ((3.411219 48.54254...      77\n2    77075 POLYGON ((2.775456 48.91034...      77\n3    77081 POLYGON ((2.738851 48.6351,...      77\n4    77151 POLYGON ((3.156655 48.6999,...      77\n5    77152 POLYGON ((2.641049 48.49468...      77\n6    77192 POLYGON ((2.896519 48.68125...      77\n\n\n\n\nEssai de cartographie\n\nplot(mapdon[\"depcode\"])\n\n\n\n\n\n\nSauvegarde au format sf\n\nsaveRDS(mapdon,\"carto/idfcom/idfcom.RDS\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html",
    "href": "22-CARTO-mapsf.html",
    "title": "CARTO-mapsf",
    "section": "",
    "text": "Le package mapsf permet de réaliser des cartes statiques de très haute qualité. Il a en effet été mis au point par des cartographes et des géomaticiens professionnels de l’UMS RIATE. Il prend la suite du package cartography dont la maintenance demeurera assuré quelque temps encore mais ne fera plus l’objet de développements futurs. Le package mapsf présente l’avantage d’être totalement compatibvle avec le package sf ce qui n’était pas autant le cas pour le package cartography, plus ancien, et créé pour être compatible avec l’ancien package sp.\nOn trouvera la documentation du package mapsf à l’adresse suivante :\nhttps://riatelab.github.io/mapsf/index.html"
  },
  {
    "objectID": "22-CARTO-mapsf.html#création-dun-template-cartographique",
    "href": "22-CARTO-mapsf.html#création-dun-template-cartographique",
    "title": "CARTO-mapsf",
    "section": "Création d’un template cartographique",
    "text": "Création d’un template cartographique\nNous allons dans un premier temps apprendre à créer un fonds de carte vierge mais comportant tout l’habillage nécessaire (“template”). Pour cela nous allons charger différentes couches cartographiques correspondant respectivement au département, aux communes et aux iris :\n\nmap_iris<-readRDS(\"carto/iris/94/map_iris_hlm.RDS\")\nmap_com <-readRDS(\"carto/iris/94/map_com_hlm.RDS\")\n\n\ntracé d’un fonds de carte vierge\n\n mf_map(map_iris, type = \"base\")\n\n\n\n\n\n\nSuperposition de couches\nOn peut toutefois ajouter toute une série de paramètres supplémentaire (col=, border=, lwd=, …) et superposer plusieurs fonds de carte avec le paramètre add = TRUE. L’ajout de la fonction layout permet de rajouter un cadre une légende.\n\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n# Ajoute un cadre, un titre et des sources\nmf_layout(title = \"Val de Marne\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\n\n\nAjout d’un thème\nOn peut finalement modifier l’ensemble de la carte en lui ajoutant une instruction mf_theme() qui peut reprendre des styles existants ( “default”, “brutal”, “ink”, “dark”, “agolalight”, “candy”, “darkula”, “iceberg”, “green”, “nevermind”, “jsk”, “barcelona”) mais aussi créer ses propres thèmes\n\n#Choix du thème\nmf_theme(\"dark\")\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\nmf_layout(title = \"Theme dark\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\nAutre exemple\n\n#Choix du thème\nmf_theme(\"agolalight\")\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\nmf_layout(title = \"Theme agolalight\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\n\n\nAjout de texte\nOn peut ajouter une couche de texte avec la fonction mf_label(). Par exemple, on va ajouter à la carte précédente le nom des communes\n\nmf_theme(\"agolalight\")\n\n# Trace les Iris avec des paramètres\nmf_map(map_iris, \n       type = \"base\", \n       col = \"lightyellow\",\n       border=\"gray80\",\n       lwd=0.3)\n\n# Ajoute les contours des communes\nmf_map(map_com, \n       type = \"base\", \n       col = NA,\n       border=\"red\",\n       lwd=1,\n       add = TRUE)\n\n# Ajoute les noms des communes\nmf_label(map_com, \n         var=\"NOM_COM\",\n         cex=0.4, \n         col=\"blue\",\n         overlap = FALSE)\n\n# Ajoute un cadre, un titre et des sources\nmf_layout(title = \"Communes et Iris du Val de Marne en 2017\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-de-stock",
    "href": "22-CARTO-mapsf.html#carte-de-stock",
    "title": "CARTO-mapsf",
    "section": "Carte de stock",
    "text": "Carte de stock\nUne carte de stock représente la localisation de quantités que l’on peut aditionner et dont le total a un sens. Par exemple un nombre d’habitants, un nombre de ménages, un nombre d’automobiles. Ce quantités doivent être représentées par des figures (cercles, carrés, …) dont la surface est proportionelle au stock afin que l’oeil du lecteur puisse les aditionner visuellement.\nDans le package mapsf, on réalise ce type de carte à l’aide de la fonction mf_map()en lui donnant le paramètre type=\"prop\".\nOn va tenter à titre d’exemple de représenter la distribution du nombre de ménages ordinaires occupant un logement HLM par IRIS :\n\nCarte de stock minimale\nLes instructions minimales sont les suivantes :\n\n# Trace les contours des communes\nmf_map(x= map_iris, \n       type = \"base\")\n\n# Ajoute le nombre de ménages par IRIS\nmf_map(x =map_iris, \n      type =\"prop\",\n      var = \"HLM1\",\n      add=TRUE)\n\n\n\n\nMais le résultat est peu satisfaisant car les cercles sont trop grands. Il faut en pratique toujours effectuer un réglage de ceux-ci avec l’instruction inches=\n\n\nCarte de stock habillée\n\nmf_theme(\"agolalight\")\nmf_map(map_iris, type = \"base\",  \n       col = \"lightyellow\",border=\"gray80\", lwd=0.3)\nmf_map(map_com, type = \"base\", \n       col = NA,border=\"black\",lwd=1,add = TRUE)\n\nmf_map(map_iris, var = \"HLM1\",type = \"prop\",\n  inches = 0.1, col = \"red\",leg_pos = \"left\",  \n  leg_title = \"Nombre de ménages\", add=TRUE)\n\nmf_layout(title = \"Distribution des logements HLM en 2017\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-choroplèthe",
    "href": "22-CARTO-mapsf.html#carte-choroplèthe",
    "title": "CARTO-mapsf",
    "section": "Carte choroplèthe",
    "text": "Carte choroplèthe\nUne carte choroplèthe ou d’intensité représente un phénomène relatif dont la somme n’a pas de sens. Par exemple, il serait absurde d’aditionner les % de logement HLM des IRIS du Val de Marne. Ces variables d’intensité caractèrisent donc l’état général d’une zone (choros) et elles vont être représentées par une couleur appliquée à toute la surface de la zone, d’où leur nom de cartes choroplèthes.\nLa fonction du package mapsf adaptée aux variables d’intensité est la fonction mf_map()munie du paramètre type = \"choro\".\nOn va prendre l’exemple du nombre de voitures par ménage.\n\nCarte choroplèthe minimale\nSi on ne précise rien, la carte est réalisée à l’aide de la palette par défaut avec un découpage des classes en quantiles (effectifs égaux).\n\n# Carte choroplèthe\nmf_map(\n  x = map_iris, \n  var = \"HLMpct\",\n  type = \"choro\")\n\n\n\n\n\n\nCarte choroplèthe habillée\nOn peut arriver à une carte beaucoup plus satisfaisante en contrôlant l’ensemble des paramètres de couleur et de découpage des classes. Puis en superposant les contours de communes au dessus de la carte des IRIS pour faciliter le repérage.\n\n# Choisir les classes et la palette\nmybreaks = c(0, 10,20,30,40,50,60,70,80,90, 100)\nmypal <- mf_get_pal(n = c(5, 5), pal = c(\"Greens\", \"Reds\"))\n# Tracer la carte choroplèthe\nmf_map( map_iris, var = \"HLMpct\",type = \"choro\",\n  breaks = mybreaks,pal = mypal,\n  border=\"white\",col_na = \"gray80\",\n leg_title = \"% logements HLM\",\n leg_val_rnd = 0)\n# Ajouter les contours des communes\nmf_map(map_com, type = \"base\", col = NA,\n       border=\"black\",lwd=1,add = TRUE)\n# Ajouter un cadre, un titre et des sources\nmf_layout(title = \"% de ménages en HLM au RP  2017\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-stock-choroplèthe",
    "href": "22-CARTO-mapsf.html#carte-stock-choroplèthe",
    "title": "CARTO-mapsf",
    "section": "Carte stock + choroplèthe",
    "text": "Carte stock + choroplèthe\n\nSuperposition\nOn peut combiner les deux modes cartographiques par superposition :\n\nmf_theme(\"agolalight\")\n\n# Choisit les classes\nmybreaks = c(0,5,10,20,40,80,100)\n\n# Trace la carte choroplèthe\nmf_map(\n  x = map_iris, \n  var = \"HLMpct\",\n  breaks = mybreaks,\n # pal=mypal,\n type = \"choro\",\n  border=\"white\",\n  col_na = \"gray80\",\n lwd=0.3,\n leg_title = \"% ménages\", \n leg_val_rnd = 0,\n  \n)\n\n# Ajoute les cercles proportionnels\n\nmf_map(\n  x =map_iris, \n  var = \"HLM1\",\n  type = \"prop\",\n  inches = 0.06, \n  col = \"red\",\n  leg_pos = \"right\",  \n  leg_title = \"Nb ménages\",\n  add=TRUE\n)\n# Ajoute les contours des communes\nmf_map(map_com, \n       type = \"base\", \n       col = NA,\n       border=\"black\",\n       lwd=1,\n       add = TRUE)\n\n# Ajoute un cadre, un titre et des sources\nmf_layout(title = \"Les ménages ordinaires en HLM  2017\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\n\n\nCombinaison\nMais on peut aussi utiliser le type prop_choro\n\nmf_theme(\"agolalight\")\nmybreaks = c(0, 10,20,30,40,50,60,70,80,90, 100)\nmypal <- mf_get_pal(n = c(5, 5), pal = c(\"Greens\", \"Reds\"))\nmf_map(map_iris, type = \"base\",  \n       col = \"gray80\",border=\"white\", lwd=0.3)\nmf_map(map_com, type = \"base\", \n       col = NA,border=\"white\",lwd=1,add = TRUE)\nmf_prop_choro( x = map_iris,  var = c(\"TOT\", \"HLMpct\"), \n  inches = 0.08, col_na = \"grey\", pal=mypal,\n  breaks = mybreaks, nbreaks = 4, lwd = 0.1,\n  leg_pos = c(\"right\", \"left\"),leg_val_rnd = c(0,0),\n  leg_title = c(\"nb. ménages\", \"% HLM\"),\n  add = TRUE)\nmf_layout(title = \"Les ménages ordinaires en HLM dans le Val de Marne au RP 2017\",\n        frame = TRUE, credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataMining2023",
    "section": "",
    "text": "Ce document est la troisième version d’un cours de Data Mining dispensé aux étudiants de deuxième année de l’ option Data Mining du master MECI .\nIl est basé sur R version 4.2.1 (2022-06-23 ucrt).\nCe document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse :\n\nhttps://claudegrasland.github.io/datamining2023/.\n\nPour toute suggestion ou correction, il est possible de me contacter par mail"
  },
  {
    "objectID": "index.html#prérequis",
    "href": "index.html#prérequis",
    "title": "DataMining2023",
    "section": "Prérequis",
    "text": "Prérequis\nLe seul prérequis pour suivre ce document est d’avoir installé R et RStudio sur votre ordinateur. Il s’agit de deux logiciels libres, gratuits, téléchargeables en ligne et fonctionnant sous PC, Mac et Linux.\nPour installer R, il suffit de se rendre sur une des pages suivantes 1 :\n\nInstaller R sous Windows\nInstaller R sous Mac\n\nPour installer RStudio, rendez-vous sur la page suivante et téléchargez la version adaptée à votre système :\n\nhttps://www.rstudio.com/products/rstudio/download/#download"
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "DataMining2023",
    "section": "Remerciements",
    "text": "Remerciements\nCe document a bénéficié de la relecture et des suggestions … des étudiants qui en ont été les cobayes des premières versions."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "DataMining2023",
    "section": "Licence",
    "text": "Licence\nCe document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.\n\n\n\nLicence Creative Commons"
  }
]